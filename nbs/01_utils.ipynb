{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa027742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4aa6afb",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec7d72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "import json\n",
    "import os\n",
    "import subprocess\n",
    "from collections import Counter, defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import yaml\n",
    "import threading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990b8ca9",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b62e0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class Dataset:\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_path: str,\n",
    "        split: str = \"train\",\n",
    "        load_cluster: bool = False,\n",
    "        return_np_array: bool = True,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Initialize dataset loader.\n",
    "\n",
    "        Args:\n",
    "            data_path (str or Path): Base path to the SemanticKITTI dataset.\n",
    "            split (str): Dataset split to use ('train', 'valid', or 'test').\n",
    "        \"\"\"\n",
    "        self.data_path: Path = Path(data_path)\n",
    "        self.split: str = split\n",
    "        self.is_test: bool = split == \"test\"\n",
    "        self.load_cluster: bool = load_cluster\n",
    "        self.return_np_array = return_np_array\n",
    "\n",
    "        # Paths to YAML config and data folders\n",
    "        self.yaml_path: Path = Path(\"../tests/semantic-kitti.yaml\")\n",
    "        # self.yaml_path: Path = self.data_path / 'semantic-kitti.yaml'\n",
    "        self.velodynes_path: Path = (\n",
    "            self.data_path / \"data_odometry_velodyne/dataset/sequences\"\n",
    "        )\n",
    "        self.labels_path: Path = (\n",
    "            self.data_path / \"data_odometry_labels/dataset/sequences\"\n",
    "        )\n",
    "        self.clusters_path: Path = (\n",
    "            self.data_path / \"data_odometry_clusters/dataset/sequences\"\n",
    "        )\n",
    "\n",
    "        # Load dataset metadata and label mappings\n",
    "        with open(self.yaml_path, \"r\") as file:\n",
    "            metadata: dict = yaml.safe_load(file)\n",
    "\n",
    "        self.sequences: list[int] = metadata[\"split\"][split]\n",
    "        self.learning_map: dict[int, int] = metadata[\"learning_map\"]\n",
    "\n",
    "        # Convert label map to numpy for fast lookup\n",
    "        max_label: int = max(self.learning_map.keys())\n",
    "        self.learning_map_np: np.ndarray = np.zeros((max_label + 1,), dtype=np.uint32)\n",
    "        for raw_label, mapped_label in self.learning_map.items():\n",
    "            self.learning_map_np[raw_label] = mapped_label\n",
    "\n",
    "        # Collect all frame paths for selected sequences\n",
    "        self.frame_paths: list[tuple[str, str]] = self._collect_frame_paths()\n",
    "\n",
    "        self.last_seq = None\n",
    "        self.last_frame_id = None\n",
    "\n",
    "    def _collect_frame_paths(self) -> \"list[tuple[str, str]]\":\n",
    "        \"\"\"Collect all (sequence, frame_id) pairs from the dataset split.\"\"\"\n",
    "        frame_list = []\n",
    "        for seq in self.sequences:\n",
    "            seq_str = f\"{int(seq):02d}\"\n",
    "            seq_velo_path = self.velodynes_path / seq_str / \"velodyne\"\n",
    "            velo_files = sorted(seq_velo_path.glob(\"*.bin\"))\n",
    "            for file in velo_files:\n",
    "                frame_list.append((seq_str, file.stem))\n",
    "        return frame_list\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"Return number of samples in the dataset split.\"\"\"\n",
    "        return len(self.frame_paths)\n",
    "\n",
    "    def _compute_scanline_ids(\n",
    "        self, point_cloud: np.ndarray, n_scans: int = 64\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Approximate scanline indices based on point order.\n",
    "\n",
    "        Args:\n",
    "            point_cloud (np.ndarray): Nx3 array of 3D points.\n",
    "            n_scans (int): Number of LiDAR scanlines (e.g., 64 for HDL-64E).\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: Nx1 array with estimated scanline indices (0 to n_scans - 1).\n",
    "        \"\"\"\n",
    "        total_points = point_cloud.shape[0]\n",
    "        scanline_ids = np.floor(\n",
    "            np.linspace(0, n_scans, total_points, endpoint=False)\n",
    "        ).astype(int)\n",
    "        return scanline_ids.reshape(-1, 1)\n",
    "\n",
    "    def get_last_seq_frame(self) -> tuple[str, str] | None:\n",
    "        \"\"\"\n",
    "        Get the last sequence and frame ID loaded.\n",
    "\n",
    "        Returns:\n",
    "            tuple: (sequence, frame_id)\n",
    "        \"\"\"\n",
    "\n",
    "        if self.last_seq is None or self.last_frame_id is None:\n",
    "            return None\n",
    "        else:\n",
    "            return self.last_seq, self.last_frame_id\n",
    "\n",
    "    def __getitem__(self, idx: int) -> \"dict[str, np.ndarray] | np.ndarray\":\n",
    "        \"\"\"\n",
    "        Load a sample from the dataset.\n",
    "\n",
    "        Args:\n",
    "            idx (int): Index of the frame to load.\n",
    "\n",
    "        Returns:\n",
    "            tuple:\n",
    "                - point_cloud_with_label (np.ndarray): Nx6 array [x, y, z, true_label, pred_label, scanline_id].\n",
    "                - item_dict (dict): Contains 'point_cloud', 'label', and 'mask'.\n",
    "        \"\"\"\n",
    "\n",
    "        seq, frame_id = self.frame_paths[idx]\n",
    "        self.last_seq = seq\n",
    "        self.last_frame_id = frame_id\n",
    "\n",
    "        # Load point cloud (Nx4), drop reflectance\n",
    "        velodyne_file_path = self.velodynes_path / seq / \"velodyne\" / f\"{frame_id}.bin\"\n",
    "        with open(velodyne_file_path, \"rb\") as file:\n",
    "            point_cloud = np.fromfile(file, dtype=np.float32).reshape(-1, 4)[:, :3]\n",
    "\n",
    "        # Load and map semantic labels\n",
    "        if not self.is_test:\n",
    "            label_file_path = self.labels_path / seq / \"labels\" / f\"{frame_id}.label\"\n",
    "            if label_file_path.exists():\n",
    "                with open(label_file_path, \"rb\") as file:\n",
    "                    raw_labels = np.fromfile(file, dtype=np.uint32) & 0xFFFF\n",
    "                labels = self.learning_map_np[raw_labels]\n",
    "                mask = labels != 0\n",
    "            else:\n",
    "                labels = np.zeros(point_cloud.shape[0], dtype=np.uint32)\n",
    "                mask = np.ones(point_cloud.shape[0], dtype=bool)\n",
    "        else:\n",
    "            labels = np.zeros(point_cloud.shape[0], dtype=np.uint32)\n",
    "            mask = np.ones(point_cloud.shape[0], dtype=bool)\n",
    "\n",
    "        # Estimate scanline indices\n",
    "        scanline_ids = self._compute_scanline_ids(point_cloud)\n",
    "\n",
    "        if self.load_cluster:\n",
    "            cluster_file_path = (\n",
    "                self.clusters_path / seq / \"clusters\" / f\"{frame_id}_cluster.label\"\n",
    "            )\n",
    "            if cluster_file_path.exists():\n",
    "                with open(cluster_file_path, \"rb\") as file:\n",
    "                    clusters = np.fromfile(file, dtype=np.uint32)\n",
    "                if clusters.shape[0] != point_cloud.shape[0]:\n",
    "                    raise ValueError(\n",
    "                        f\"Predicted label count mismatch for frame {seq}/{frame_id}\"\n",
    "                    )\n",
    "                clusters = clusters.reshape(-1, 1)\n",
    "            else:\n",
    "                clusters = np.zeros((point_cloud.shape[0], 1), dtype=np.uint32)\n",
    "        else:\n",
    "            clusters = np.zeros((point_cloud.shape[0], 1), dtype=np.uint32)\n",
    "\n",
    "        # # Final format: [x, y, z, true_label, predicted_label, scanline_id]\n",
    "        point_cloud_array = np.hstack(\n",
    "            (point_cloud, labels.reshape(-1, 1), clusters, scanline_ids)\n",
    "        )\n",
    "\n",
    "        item_dict = {\n",
    "            \"point_cloud\": point_cloud,\n",
    "            \"label\": labels,\n",
    "            \"cluster\": clusters,\n",
    "            \"scanline_id\": scanline_ids,\n",
    "            \"mask\": mask,\n",
    "        }\n",
    "\n",
    "        if self.return_np_array:\n",
    "            return point_cloud_array\n",
    "        else:\n",
    "            return item_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52091605",
   "metadata": {},
   "source": [
    "# Visualizer for Point Clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb63aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class PointCloudVisualizer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        point_size: float = 1.0,\n",
    "        grid_size=50,\n",
    "        grid_spacing=1.0,\n",
    "        grid_line_width=10,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Visualizer class for rendering point clouds using Open3D with color-coded semantic labels.\n",
    "\n",
    "        Args:\n",
    "            point_size (float): Default size of points in the Open3D viewer.\n",
    "        \"\"\"\n",
    "        self.point_size = point_size\n",
    "        self.fixed_colors_rgb = self._get_fixed_colors_rgb()\n",
    "        self.grid_size = grid_size\n",
    "        self.grid_spacing = grid_spacing\n",
    "        self.grid_line_width = grid_line_width\n",
    "\n",
    "    def set_point_sieze(self, point_size):\n",
    "        self.point_size = point_size\n",
    "\n",
    "    def set_grid_size(self, grid_size):\n",
    "        self.grid_size = grid_size\n",
    "\n",
    "    def set_grid_spacing(self, grid_spacing):\n",
    "        self.grid_spacing = grid_spacing\n",
    "\n",
    "    def set_grid_line_width(self, grid_line_width):\n",
    "        self.grid_line_width = grid_line_width\n",
    "\n",
    "    def _get_fixed_colors_rgb(self) -> \"dict[int, list[float]]\":\n",
    "        fixed_colors = {\n",
    "            -1: [255, 255, 255],  # plane\n",
    "            0: [0, 0, 0],  # unlabeled\n",
    "            1: [245, 150, 100],  # car\n",
    "            2: [245, 230, 100],  # bicycle\n",
    "            3: [150, 60, 30],  # motorcycle\n",
    "            4: [180, 30, 80],  # truck\n",
    "            5: [250, 80, 100],  # other-vehicle\n",
    "            6: [30, 30, 255],  # person\n",
    "            7: [200, 40, 255],  # bicyclist\n",
    "            8: [90, 30, 150],  # motorcyclist\n",
    "            9: [255, 0, 255],  # road\n",
    "            10: [255, 150, 255],  # parking\n",
    "            11: [75, 0, 75],  # sidewalk\n",
    "            12: [75, 0, 175],  # other-ground\n",
    "            13: [0, 200, 255],  # building\n",
    "            14: [50, 120, 255],  # fence\n",
    "            15: [0, 175, 0],  # vegetation\n",
    "            16: [0, 60, 135],  # trunk\n",
    "            17: [80, 240, 150],  # terrain\n",
    "            18: [150, 240, 255],  # pole\n",
    "            19: [0, 0, 255],  # traffic-sign\n",
    "        }\n",
    "        return {\n",
    "            label: [c / 255.0 for c in reversed(rgb)]\n",
    "            for label, rgb in fixed_colors.items()\n",
    "        }\n",
    "\n",
    "    def _get_color_map(self, labels: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Assigns RGB colors to labels.\n",
    "\n",
    "        Args:\n",
    "            labels (np.ndarray): Array of label ids.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: Nx3 array of RGB colors.\n",
    "        \"\"\"\n",
    "        color_map = np.zeros((labels.shape[0], 3))\n",
    "        for i, label in enumerate(labels):\n",
    "            if label in self.fixed_colors_rgb:\n",
    "                color_map[i] = self.fixed_colors_rgb[label]\n",
    "            else:\n",
    "                rng = np.random.default_rng(label)\n",
    "                color_map[i] = rng.random(3)\n",
    "        return color_map\n",
    "\n",
    "    def _create_grid(self, grid_size=50, grid_spacing=1.0):\n",
    "        points = []\n",
    "        lines = []\n",
    "        colors = []\n",
    "\n",
    "        for i in range(-grid_size, grid_size + 1):\n",
    "            # Linhas paralelas ao eixo X\n",
    "            points.append([i * grid_spacing, -grid_size * grid_spacing, 0])\n",
    "            points.append([i * grid_spacing, grid_size * grid_spacing, 0])\n",
    "            lines.append([len(points) - 2, len(points) - 1])\n",
    "\n",
    "            # Linhas paralelas ao eixo Y\n",
    "            points.append([-grid_size * grid_spacing, i * grid_spacing, 0])\n",
    "            points.append([grid_size * grid_spacing, i * grid_spacing, 0])\n",
    "            lines.append([len(points) - 2, len(points) - 1])\n",
    "\n",
    "            # Cores: mais clara a cada 10 unidades\n",
    "            color = [0.3, 0.3, 0.3] if i % 10 else [0.6, 0.6, 0.6]\n",
    "            colors.extend([color, color])\n",
    "\n",
    "        grid = o3d.geometry.LineSet()\n",
    "        grid.points = o3d.utility.Vector3dVector(points)\n",
    "        grid.lines = o3d.utility.Vector2iVector(lines)\n",
    "        grid.colors = o3d.utility.Vector3dVector(colors)\n",
    "        return grid\n",
    "\n",
    "    def _create_plane(self, normal_d_tuple, size=100.0):\n",
    "        \"\"\"\n",
    "        Cria um plano baseado no vetor normal e no valor d.\n",
    "\n",
    "        Args:\n",
    "            normal_d_tuple (tuple): Tuple contendo o vetor normal (x, y, z) e o valor d.\n",
    "            size (float): Tamanho do plano a ser desenhado.\n",
    "\n",
    "        Returns:\n",
    "            o3d.geometry.TriangleMesh: Mesh do plano.\n",
    "        \"\"\"\n",
    "        normal, d = normal_d_tuple\n",
    "\n",
    "        # Normalizar o vetor normal\n",
    "        normal = np.array(normal)\n",
    "        normal = normal / np.linalg.norm(normal)\n",
    "\n",
    "        # Calcular 4 pontos do plano\n",
    "        p1 = np.array(\n",
    "            [-size, -size, -(normal[0] * (-size) + normal[1] * (-size) + d) / normal[2]]\n",
    "        )\n",
    "        p2 = np.array(\n",
    "            [size, -size, -(normal[0] * size + normal[1] * (-size) + d) / normal[2]]\n",
    "        )\n",
    "        p3 = np.array(\n",
    "            [size, size, -(normal[0] * size + normal[1] * size + d) / normal[2]]\n",
    "        )\n",
    "        p4 = np.array(\n",
    "            [-size, size, -(normal[0] * (-size) + normal[1] * size + d) / normal[2]]\n",
    "        )\n",
    "\n",
    "        # Criar os pontos para o mesh\n",
    "        points = np.vstack((p1, p2, p3, p4))\n",
    "\n",
    "        # Criar os triângulos que formam o plano\n",
    "        triangles = [[0, 1, 2], [0, 2, 3]]  # Triângulo 1  # Triângulo 2\n",
    "\n",
    "        # Criar a malha triangular\n",
    "        plane_mesh = o3d.geometry.TriangleMesh()\n",
    "        plane_mesh.vertices = o3d.utility.Vector3dVector(points)\n",
    "        plane_mesh.triangles = o3d.utility.Vector3iVector(triangles)\n",
    "\n",
    "        # Colorir a malha do plano de azul\n",
    "        plane_mesh.paint_uniform_color([0.45, 0.45, 0.45])\n",
    "\n",
    "        return plane_mesh\n",
    "\n",
    "    def _create_axis_arrow(self, length=1.0, color=[1, 0, 0], rotation=None):\n",
    "        arrow = o3d.geometry.TriangleMesh.create_arrow(\n",
    "            cylinder_radius=0.01,\n",
    "            cone_radius=0.03,\n",
    "            cylinder_height=length * 0.8,\n",
    "            cone_height=length * 0.2,\n",
    "        )\n",
    "        arrow.compute_vertex_normals()\n",
    "        arrow.paint_uniform_color(color)\n",
    "        if rotation is not None:\n",
    "            arrow.rotate(rotation, center=(0, 0, 0))\n",
    "        return arrow\n",
    "\n",
    "    def show(self, *args, **kwargs):\n",
    "        thread = threading.Thread(\n",
    "            target=self.show_point_cloud, args=args, kwargs=kwargs\n",
    "        )\n",
    "        thread.start()\n",
    "\n",
    "    def show_point_cloud(\n",
    "        self,\n",
    "        point_cloud: np.ndarray,\n",
    "        normal_d_tuple: tuple | None = None,\n",
    "        show_true_label: bool = False,\n",
    "        show_ground: bool = True,\n",
    "        show_clusters: bool = True,\n",
    "        show_unlabeled: bool = True,\n",
    "        show_plane: bool = False,\n",
    "        show_grid: bool = False,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Visualize the filtered point cloud using Open3D.\n",
    "\n",
    "        Args:\n",
    "            point_cloud (np.ndarray): N x 6 array [x, y, z, true_label, pred_label, scanline_id].\n",
    "        \"\"\"\n",
    "\n",
    "        label_col = 3 if show_true_label else 4\n",
    "        labels = point_cloud[:, label_col]\n",
    "\n",
    "        # Apply filter mask\n",
    "        mask = (\n",
    "            (show_plane & (labels == -1))\n",
    "            | (show_unlabeled & (labels == 0))\n",
    "            | (show_ground & (labels == 9))\n",
    "            | (show_clusters & (labels >= 1) & (labels != 9))\n",
    "        )\n",
    "\n",
    "        xyz = point_cloud[mask, :3]\n",
    "        visible_labels = labels[mask].astype(int)\n",
    "        colors = self._get_color_map(visible_labels)\n",
    "\n",
    "        # Visualize with point size\n",
    "        vis = o3d.visualization.Visualizer()  # type: ignore\n",
    "        vis.create_window(window_name=\"Plane Visualization\", width=800, height=600)\n",
    "\n",
    "        opt = vis.get_render_option()\n",
    "        opt.point_size = self.point_size\n",
    "        opt.background_color = np.asarray([0.1, 0.1, 0.1])  # estilo AutoCAD / pptk\n",
    "        opt.show_coordinate_frame = True\n",
    "        opt.mesh_show_back_face = True  # Exibir o lado de trás do plano\n",
    "\n",
    "        # extrair para uma funcao\n",
    "        # X (vermelho): rotaciona -90° ao redor Z\n",
    "        arrow_x = self._create_axis_arrow(\n",
    "            length=1.0,\n",
    "            color=[1, 0, 0],\n",
    "            rotation=o3d.geometry.get_rotation_matrix_from_xyz([0, np.pi / 2, 0]),\n",
    "        )\n",
    "        # Y (verde): rotaciona +90° ao redor X\n",
    "        arrow_y = self._create_axis_arrow(\n",
    "            length=1.0,\n",
    "            color=[0, 1, 0],\n",
    "            rotation=o3d.geometry.get_rotation_matrix_from_xyz([-np.pi / 2, 0, 0]),\n",
    "        )\n",
    "        # Z (azul): já está na direção Z por padrão\n",
    "        arrow_z = self._create_axis_arrow(length=1.0, color=[0, 0, 1], rotation=None)\n",
    "        vis.add_geometry(arrow_x)\n",
    "        vis.add_geometry(arrow_y)\n",
    "        vis.add_geometry(arrow_z)\n",
    "\n",
    "        # Create Open3D point cloud\n",
    "        pcd = o3d.geometry.PointCloud()\n",
    "        pcd.points = o3d.utility.Vector3dVector(xyz)\n",
    "        pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "        vis.add_geometry(pcd)\n",
    "\n",
    "        if show_grid:\n",
    "            vis.add_geometry(\n",
    "                self._create_grid(self.grid_size, self.grid_spacing)\n",
    "            )  # grid grande com espaçamento 1m\n",
    "            opt.line_width = self.grid_line_width\n",
    "        if show_plane and normal_d_tuple != None:\n",
    "            vis.add_geometry(self._create_plane(normal_d_tuple))\n",
    "\n",
    "        vis.run()\n",
    "        vis.destroy_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c68ebcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def rodar_visualizador(point_cloud, normal_d_tuple=None, **visualizer_params):\n",
    "    temp_dir = \"temp_vis\"\n",
    "    os.makedirs(temp_dir, exist_ok=True)\n",
    "\n",
    "    # Salvar nuvem de pontos\n",
    "    np.save(os.path.join(temp_dir, \"point_cloud.npy\"), point_cloud)\n",
    "\n",
    "    # Salvar plano (normal + d)\n",
    "    if normal_d_tuple:\n",
    "        normal_d = np.array([*normal_d_tuple[0], normal_d_tuple[1]])\n",
    "        np.save(os.path.join(temp_dir, \"normal_d.npy\"), normal_d)\n",
    "\n",
    "    # Salvar parâmetros\n",
    "    with open(os.path.join(temp_dir, \"visualizer_config.json\"), \"w\") as f:\n",
    "        json.dump(visualizer_params, f)\n",
    "\n",
    "    # Rodar visualizador em subprocesso\n",
    "    comando = [\"python3\", \"visualizer.py\", temp_dir]\n",
    "    thread = threading.Thread(target=lambda: subprocess.run(comando))\n",
    "    thread.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3006ca",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11dd636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def save_clusters(\n",
    "    point_cloud: np.ndarray, seq: str, frame_id: str, output_base_path: str\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Salva os rótulos preditos em formato .label seguindo a estrutura do SemanticKITTI.\n",
    "\n",
    "    Args:\n",
    "        point_cloud (np.ndarray): Array Nx6 com colunas [x, y, z, true_label, predicted_label, scanline_index].\n",
    "        seq (str): Número da sequência (ex: '00', '01', ...).\n",
    "        frame_id (str): ID do frame (ex: '000123').\n",
    "        output_base_path (str): Caminho base até `data_odometry_cluster_pred/dataset/sequences`.\n",
    "    \"\"\"\n",
    "    # Extrair coluna de predição (índice 4)\n",
    "    predicted_labels = point_cloud[:, 4].astype(np.uint32)\n",
    "\n",
    "    # Construir caminho de saída\n",
    "    output_dir = Path(output_base_path) / seq / \"clusters\"\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Nome do arquivo com sufixo _pred.label\n",
    "    output_file = output_dir / f\"{frame_id}_cluster.label\"\n",
    "\n",
    "    # Salvar como arquivo binário .label\n",
    "    predicted_labels.tofile(output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b220da2e",
   "metadata": {},
   "source": [
    "# Result analisys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0207163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def verificar_consistencia_labels(pontos):\n",
    "    \"\"\"\n",
    "    Verifica inconsistências entre rótulos verdadeiros e clusters atribuídos.\n",
    "    Também calcula estatísticas (média e desvio padrão) dos clusters inconsistentes.\n",
    "\n",
    "    Retorna:\n",
    "        - inconsistentes_total (int): número de clusters inconsistentes\n",
    "        - combinacoes_contadas (Counter): contagem de combinações de labels inconsistentes\n",
    "        - estatisticas_erro (dict): médias e desvios padrão das métricas de erro\n",
    "    \"\"\"\n",
    "    labels_pred = pontos[:, 4].astype(int)\n",
    "    labels_true = pontos[:, 3].astype(int)\n",
    "\n",
    "    pares = np.stack((labels_pred, labels_true), axis=1)\n",
    "\n",
    "    cluster_to_true_labels = defaultdict(list)\n",
    "    for cluster_id, true_label in pares:\n",
    "        cluster_to_true_labels[cluster_id].append(true_label)\n",
    "\n",
    "    combinacoes = []\n",
    "    inconsistentes_total = 0\n",
    "\n",
    "    # Para calcular as médias e desvios depois\n",
    "    lista_total_pontos = []\n",
    "    lista_pontos_label_dominante = []\n",
    "    lista_erro_percentual = []\n",
    "\n",
    "    for cluster_id, labels in cluster_to_true_labels.items():\n",
    "        if cluster_id == 9:\n",
    "            continue  # Ignorar o solo\n",
    "\n",
    "        labels_sem_unlabeled = [l for l in labels if l != 0]\n",
    "\n",
    "        if len(set(labels_sem_unlabeled)) > 1:\n",
    "            inconsistentes_total += 1\n",
    "\n",
    "            # Cria combinação ordenada para agrupar\n",
    "            combinacao = tuple(sorted(set(labels_sem_unlabeled)))\n",
    "            combinacoes.append(combinacao)\n",
    "\n",
    "            # Estatísticas de erro\n",
    "            total_pontos = len(labels)\n",
    "            contador_labels = Counter(labels_sem_unlabeled)\n",
    "            label_dominante, pontos_label_dominante = contador_labels.most_common(1)[0]\n",
    "            erro_percentual = 100 * (1 - (pontos_label_dominante / total_pontos))\n",
    "\n",
    "            lista_total_pontos.append(total_pontos)\n",
    "            lista_pontos_label_dominante.append(pontos_label_dominante)\n",
    "            lista_erro_percentual.append(erro_percentual)\n",
    "\n",
    "    combinacoes_contadas = Counter(combinacoes)\n",
    "\n",
    "    # Se não houver inconsistentes, evita erro de divisão\n",
    "    if inconsistentes_total > 0:\n",
    "        estatisticas_erro = {\n",
    "            \"media_total_pontos\": np.mean(lista_total_pontos),\n",
    "            \"std_total_pontos\": np.std(lista_total_pontos),\n",
    "            \"media_pontos_label_dominante\": np.mean(lista_pontos_label_dominante),\n",
    "            \"std_pontos_label_dominante\": np.std(lista_pontos_label_dominante),\n",
    "            \"media_erro_percentual\": np.mean(lista_erro_percentual),\n",
    "            \"std_erro_percentual\": np.std(lista_erro_percentual),\n",
    "        }\n",
    "    else:\n",
    "        estatisticas_erro = {\n",
    "            \"media_total_pontos\": 0,\n",
    "            \"std_total_pontos\": 0,\n",
    "            \"media_pontos_label_dominante\": 0,\n",
    "            \"std_pontos_label_dominante\": 0,\n",
    "            \"media_erro_percentual\": 0,\n",
    "            \"std_erro_percentual\": 0,\n",
    "        }\n",
    "\n",
    "    return inconsistentes_total, combinacoes_contadas, estatisticas_erro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5623b3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def get_statistics(idx, point_cloud):\n",
    "    clusters = point_cloud[:, 4]\n",
    "    num_clusters = len(np.unique(clusters))\n",
    "    num_pontos = point_cloud.shape[0]\n",
    "\n",
    "    cluster_sizes = [np.sum(clusters == label) for label in np.unique(clusters)]\n",
    "    cluster_sizes_sorted = sorted(cluster_sizes, reverse=True)\n",
    "\n",
    "    ground_cluster_size = np.sum(clusters == 9)\n",
    "    largest_non_ground_cluster = (\n",
    "        cluster_sizes_sorted[1]\n",
    "        if cluster_sizes_sorted[0] == ground_cluster_size\n",
    "        and len(cluster_sizes_sorted) > 1\n",
    "        else cluster_sizes_sorted[0]\n",
    "    )\n",
    "\n",
    "    num_clusters_inconsistentes, combinacoes, erros_clusters = (\n",
    "        verificar_consistencia_labels(point_cloud)\n",
    "    )\n",
    "\n",
    "    estatisticas_do_frame = {\n",
    "        \"frame_id\": idx,\n",
    "        \"num_clusters\": num_clusters,\n",
    "        \"num_pontos\": num_pontos,\n",
    "        \"pontos_por_cluster_medio\": (\n",
    "            num_pontos / num_clusters if num_clusters > 0 else 0\n",
    "        ),\n",
    "        \"largest_non_ground_cluster\": largest_non_ground_cluster,\n",
    "        \"gound_cluster_size\": ground_cluster_size,\n",
    "        \"num_clusters_inconsistentes\": num_clusters_inconsistentes,  # Novo campo\n",
    "        \"combinacoes\": combinacoes,\n",
    "        \"erros_clusters\": erros_clusters,\n",
    "    }\n",
    "\n",
    "    return estatisticas_do_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7105856",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ad8e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def plot_1(resumo_por_frame, seq_value=None):\n",
    "    \"\"\"\n",
    "    Plota em 4 subplots verticais:\n",
    "    1. Número total de pontos\n",
    "    2. Número total de clusters\n",
    "    3. Pontos por cluster médio\n",
    "    4. Porcentagem de redução da dimensionalidade\n",
    "    \"\"\"\n",
    "\n",
    "    # Extrair dados\n",
    "    num_clusters = np.array([f[\"num_clusters\"] for f in resumo_por_frame])\n",
    "    num_pontos = np.array([f[\"num_pontos\"] for f in resumo_por_frame])\n",
    "    pontos_por_cluster_medio = np.array(\n",
    "        [f[\"pontos_por_cluster_medio\"] for f in resumo_por_frame]\n",
    "    )\n",
    "    frames = np.arange(len(resumo_por_frame))\n",
    "\n",
    "    # Calcular a redução de dimensionalidade\n",
    "    reducao_dimensionalidade = 1 - (num_clusters / num_pontos)\n",
    "\n",
    "    # Criar subplots\n",
    "    fig, axs = plt.subplots(4, 1, figsize=(12, 18))  # 4 linhas, 1 coluna\n",
    "    fig.tight_layout(pad=5.0)\n",
    "\n",
    "    # Plot 1 - Número de pontos\n",
    "    media_pontos = np.mean(num_pontos)\n",
    "    desvio_pontos = np.std(num_pontos)\n",
    "    axs[0].plot(frames, num_pontos, marker=\"o\", label=\"Número de Pontos\", color=\"green\")\n",
    "    axs[0].axhline(\n",
    "        media_pontos, color=\"red\", linestyle=\"--\", label=f\"Média = {media_pontos:.1f}\"\n",
    "    )\n",
    "    axs[0].fill_between(\n",
    "        frames,\n",
    "        media_pontos - desvio_pontos,\n",
    "        media_pontos + desvio_pontos,\n",
    "        color=\"red\",\n",
    "        alpha=0.2,\n",
    "        label=f\"Desvio = {desvio_pontos:.1f}\",\n",
    "    )\n",
    "    axs[0].set_title(\"Número de Pontos por Frame\")\n",
    "    axs[0].set_xlabel(\"Frame\")\n",
    "    axs[0].set_ylabel(\"Número de Pontos\")\n",
    "    axs[0].legend()\n",
    "    axs[0].grid(True)\n",
    "\n",
    "    # Plot 2 - Número de clusters\n",
    "    media_clusters = np.mean(num_clusters)\n",
    "    desvio_clusters = np.std(num_clusters)\n",
    "    axs[1].plot(\n",
    "        frames, num_clusters, marker=\"o\", label=\"Número de Clusters\", color=\"blue\"\n",
    "    )\n",
    "    axs[1].axhline(\n",
    "        media_clusters,\n",
    "        color=\"blue\",\n",
    "        linestyle=\"--\",\n",
    "        label=f\"Média = {media_clusters:.1f}\",\n",
    "    )\n",
    "    axs[1].fill_between(\n",
    "        frames,\n",
    "        media_clusters - desvio_clusters,\n",
    "        media_clusters + desvio_clusters,\n",
    "        color=\"blue\",\n",
    "        alpha=0.2,\n",
    "        label=f\"Desvio = {desvio_clusters:.1f}\",\n",
    "    )\n",
    "    axs[1].set_title(\"Número de Clusters por Frame\")\n",
    "    axs[1].set_xlabel(\"Frame\")\n",
    "    axs[1].set_ylabel(\"Número de Clusters\")\n",
    "    axs[1].legend()\n",
    "    axs[1].grid(True)\n",
    "\n",
    "    # Plot 3 - Pontos por cluster médio\n",
    "    media_ppc = np.mean(pontos_por_cluster_medio)\n",
    "    desvio_ppc = np.std(pontos_por_cluster_medio)\n",
    "    axs[2].plot(\n",
    "        frames,\n",
    "        pontos_por_cluster_medio,\n",
    "        marker=\"o\",\n",
    "        label=\"Pontos por Cluster Médio\",\n",
    "        color=\"orange\",\n",
    "    )\n",
    "    axs[2].axhline(\n",
    "        media_ppc, color=\"orange\", linestyle=\"--\", label=f\"Média = {media_ppc:.1f}\"\n",
    "    )\n",
    "    axs[2].fill_between(\n",
    "        frames,\n",
    "        media_ppc - desvio_ppc,\n",
    "        media_ppc + desvio_ppc,\n",
    "        color=\"orange\",\n",
    "        alpha=0.2,\n",
    "        label=f\"Desvio = {desvio_ppc:.1f}\",\n",
    "    )\n",
    "    axs[2].set_title(\"Média de Pontos por Cluster por Frame\")\n",
    "    axs[2].set_xlabel(\"Frame\")\n",
    "    axs[2].set_ylabel(\"Pontos por Cluster\")\n",
    "    axs[2].legend()\n",
    "    axs[2].grid(True)\n",
    "\n",
    "    # Plot 4 - Redução da dimensionalidade\n",
    "    media_reducao = np.mean(reducao_dimensionalidade)\n",
    "    desvio_reducao = np.std(reducao_dimensionalidade)\n",
    "    axs[3].plot(\n",
    "        frames,\n",
    "        reducao_dimensionalidade * 100,\n",
    "        marker=\"o\",\n",
    "        label=\"Redução Dimensionalidade (%)\",\n",
    "        color=\"purple\",\n",
    "    )\n",
    "    axs[3].axhline(\n",
    "        media_reducao * 100,\n",
    "        color=\"purple\",\n",
    "        linestyle=\"--\",\n",
    "        label=f\"Média = {media_reducao*100:.2f}%\",\n",
    "    )\n",
    "    axs[3].fill_between(\n",
    "        frames,\n",
    "        (media_reducao - desvio_reducao) * 100,\n",
    "        (media_reducao + desvio_reducao) * 100,\n",
    "        color=\"purple\",\n",
    "        alpha=0.2,\n",
    "        label=f\"Desvio = {desvio_reducao*100:.2f}%\",\n",
    "    )\n",
    "    axs[3].set_title(\"Porcentagem de Redução da Dimensionalidade por Frame\")\n",
    "    axs[3].set_xlabel(\"Frame\")\n",
    "    axs[3].set_ylabel(\"Redução (%)\")\n",
    "    axs[3].legend()\n",
    "    axs[3].grid(True)\n",
    "\n",
    "    # Ajuste layout final\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    if seq_value is not None:\n",
    "        Path(\"plots\").mkdir(parents=True, exist_ok=True)\n",
    "        Path(f\"plots/{seq_value}\").mkdir(parents=True, exist_ok=True)\n",
    "        # Salvar o gráfico\n",
    "        plt.savefig(f\"plots/{seq_value}/plot-1.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f28b501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def plot_2(resumo_por_frame, seq_value=None):\n",
    "    gound_cluster_size = [f[\"gound_cluster_size\"] for f in resumo_por_frame]\n",
    "    largest_non_ground_cluster = [\n",
    "        f[\"largest_non_ground_cluster\"] for f in resumo_por_frame\n",
    "    ]\n",
    "\n",
    "    def get_stats(values):\n",
    "        return np.mean(values), np.std(values)\n",
    "\n",
    "    mean_9, std_9 = get_stats(gound_cluster_size)\n",
    "    mean_second, std_second = get_stats(largest_non_ground_cluster)\n",
    "\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(12, 10), sharex=True)\n",
    "\n",
    "    # Cluster 9\n",
    "    axs[0].plot(gound_cluster_size, marker=\"o\", label=\"Ground cluster\")\n",
    "    axs[0].axhline(mean_9, color=\"green\", linestyle=\"--\", label=f\"Média = {mean_9:.1f}\")\n",
    "    axs[0].fill_between(\n",
    "        range(len(gound_cluster_size)),\n",
    "        mean_9 - std_9,\n",
    "        mean_9 + std_9,\n",
    "        color=\"green\",\n",
    "        alpha=0.2,\n",
    "        label=f\"Desvio = {std_9:.1f}\",\n",
    "    )\n",
    "    axs[0].set_ylabel(\"Tamanho\")\n",
    "    axs[0].set_title(\"Tamanho do Ground Cluster\")\n",
    "    axs[0].legend()\n",
    "    axs[0].grid(True)\n",
    "\n",
    "    # Segundo maior\n",
    "    axs[1].plot(\n",
    "        largest_non_ground_cluster, marker=\"o\", label=\"Maior non ground cluster\"\n",
    "    )\n",
    "    axs[1].axhline(\n",
    "        mean_second, color=\"blue\", linestyle=\"--\", label=f\"Média = {mean_second:.1f}\"\n",
    "    )\n",
    "    axs[1].fill_between(\n",
    "        range(len(largest_non_ground_cluster)),\n",
    "        mean_second - std_second,\n",
    "        mean_second + std_second,\n",
    "        color=\"blue\",\n",
    "        alpha=0.2,\n",
    "        label=f\"Desvio = {std_second:.1f}\",\n",
    "    )\n",
    "    axs[1].set_ylabel(\"Tamanho\")\n",
    "    axs[1].set_title(\"Tamanho do Maior non Ground Cluster\")\n",
    "    axs[1].legend()\n",
    "    axs[1].grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    if seq_value is not None:\n",
    "        Path(\"plots\").mkdir(parents=True, exist_ok=True)\n",
    "        Path(f\"plots/{seq_value}\").mkdir(parents=True, exist_ok=True)\n",
    "        # Salvar o gráfico\n",
    "        fig.savefig(f\"plots/{seq_value}/plot-2.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dacd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def plot_3(resumo_por_frame, seq_value=None):\n",
    "    \"\"\"\n",
    "    Plota a quantidade de clusters inconsistentes por frame,\n",
    "    incluindo média e desvio padrão, juntamente com a porcentagem de erro.\n",
    "    \"\"\"\n",
    "    inconsistentes_por_frame = np.array(\n",
    "        [frame[\"num_clusters_inconsistentes\"] for frame in resumo_por_frame]\n",
    "    )\n",
    "    num_clusters_por_frame = np.array(\n",
    "        [frame[\"num_clusters\"] for frame in resumo_por_frame]\n",
    "    )\n",
    "\n",
    "    # Calcular a porcentagem de erro\n",
    "    porcentagem_erro = 1 - (inconsistentes_por_frame / num_clusters_por_frame)\n",
    "    porcentagem_erro = np.clip(porcentagem_erro, 0, 1)\n",
    "\n",
    "    # Média e desvio padrão de inconsistências\n",
    "    media_inconsistencias = np.mean(inconsistentes_por_frame)\n",
    "    desvio_inconsistencias = np.std(inconsistentes_por_frame)\n",
    "\n",
    "    # Média e desvio padrão de porcentagem de erro\n",
    "    media_erro = np.mean(porcentagem_erro)\n",
    "    desvio_erro = np.std(porcentagem_erro)\n",
    "\n",
    "    # --- Aqui a mudança ---\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(10, 10), sharex=True)\n",
    "\n",
    "    # Gráfico de inconsistências\n",
    "    axs[0].plot(inconsistentes_por_frame, marker=\"o\", label=\"Inconsistências por frame\")\n",
    "    axs[0].axhline(\n",
    "        media_inconsistencias,\n",
    "        color=\"red\",\n",
    "        linestyle=\"--\",\n",
    "        label=f\"Média = {media_inconsistencias:.2f}\",\n",
    "    )\n",
    "    axs[0].fill_between(\n",
    "        range(len(inconsistentes_por_frame)),\n",
    "        media_inconsistencias - desvio_inconsistencias,\n",
    "        media_inconsistencias + desvio_inconsistencias,\n",
    "        color=\"red\",\n",
    "        alpha=0.2,\n",
    "        label=f\"Desvio padrão = {desvio_inconsistencias:.2f}\",\n",
    "    )\n",
    "    axs[0].set_title(\"Clusters Inconsistentes por Frame\")\n",
    "    axs[0].set_xlabel(\"Frame\")\n",
    "    axs[0].set_ylabel(\"Nº de Clusters Inconsistentes\")\n",
    "    axs[0].grid(True)\n",
    "    axs[0].legend()\n",
    "\n",
    "    # Gráfico de porcentagem de erro\n",
    "    axs[1].plot(\n",
    "        porcentagem_erro,\n",
    "        marker=\"o\",\n",
    "        label=\"Porcentagem de acerto dado quantidade de clusters\",\n",
    "    )\n",
    "    axs[1].axhline(\n",
    "        media_erro, color=\"green\", linestyle=\"--\", label=f\"Média = {media_erro:.2f}\"\n",
    "    )\n",
    "    axs[1].fill_between(\n",
    "        range(len(porcentagem_erro)),\n",
    "        media_erro - desvio_erro,\n",
    "        media_erro + desvio_erro,\n",
    "        color=\"green\",\n",
    "        alpha=0.2,\n",
    "        label=f\"Desvio padrão = {desvio_erro:.2f}\",\n",
    "    )\n",
    "    axs[1].set_title(\"Porcentagem de Erro por Frame\")\n",
    "    axs[1].set_xlabel(\"Frame\")\n",
    "    axs[1].set_ylabel(\"Porcentagem de Erro\")\n",
    "    axs[1].grid(True)\n",
    "    axs[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    # Salvar antes de mostrar\n",
    "    if seq_value is not None:\n",
    "        Path(\"plots\").mkdir(parents=True, exist_ok=True)\n",
    "        Path(f\"plots/{seq_value}\").mkdir(parents=True, exist_ok=True)\n",
    "        # Salvar o gráfico\n",
    "        fig.savefig(f\"plots/{seq_value}/plot-3.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9856ff4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def plot_4(resumo_por_frame, seq_value=None):\n",
    "    \"\"\"\n",
    "    Plota três métricas de erro em subplots separados, mas no mesmo figure.\n",
    "    \"\"\"\n",
    "\n",
    "    # Configurações para as 3 métricas\n",
    "    metricas = [\n",
    "        {\n",
    "            \"chave_media\": \"media_total_pontos\",\n",
    "            \"chave_std\": \"std_total_pontos\",\n",
    "            \"titulo\": \"Total de Pontos nos Clusters Inconsistentes por Frame\",\n",
    "            \"ylabel\": \"Total de Pontos\",\n",
    "        },\n",
    "        {\n",
    "            \"chave_media\": \"media_pontos_label_dominante\",\n",
    "            \"chave_std\": \"std_pontos_label_dominante\",\n",
    "            \"titulo\": \"Pontos do Label Dominante por Cluster Inconsistente\",\n",
    "            \"ylabel\": \"Pontos do Label Dominante\",\n",
    "        },\n",
    "        {\n",
    "            \"chave_media\": \"media_erro_percentual\",\n",
    "            \"chave_std\": \"std_erro_percentual\",\n",
    "            \"titulo\": \"Erro Percentual nos Clusters Inconsistentes por Frame\",\n",
    "            \"ylabel\": \"Erro Percentual (%)\",\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    # Criar subplots\n",
    "    fig, axs = plt.subplots(3, 1, figsize=(12, 15))  # 3 linhas, 1 coluna\n",
    "    fig.tight_layout(pad=5.0)\n",
    "\n",
    "    for idx, config in enumerate(metricas):\n",
    "        chave_media = config[\"chave_media\"]\n",
    "        chave_std = config[\"chave_std\"]\n",
    "        titulo = config[\"titulo\"]\n",
    "        ylabel = config[\"ylabel\"]\n",
    "\n",
    "        metricas_por_frame = np.array(\n",
    "            [frame[\"erros_clusters\"][chave_media] for frame in resumo_por_frame]\n",
    "        )\n",
    "        media_global = np.mean(metricas_por_frame)\n",
    "        desvio_global = np.std(metricas_por_frame)\n",
    "\n",
    "        ax = axs[idx]\n",
    "        ax.plot(metricas_por_frame, marker=\"o\", label=f\"{ylabel} por frame\")\n",
    "        ax.axhline(\n",
    "            media_global,\n",
    "            color=\"red\",\n",
    "            linestyle=\"--\",\n",
    "            label=f\"Média = {media_global:.2f}\",\n",
    "        )\n",
    "        ax.fill_between(\n",
    "            range(len(metricas_por_frame)),\n",
    "            media_global - desvio_global,\n",
    "            media_global + desvio_global,\n",
    "            color=\"red\",\n",
    "            alpha=0.2,\n",
    "            label=f\"Desvio padrão = {desvio_global:.2f}\",\n",
    "        )\n",
    "        ax.set_title(titulo)\n",
    "        ax.set_xlabel(\"Frame\")\n",
    "        ax.set_ylabel(ylabel)\n",
    "        ax.legend()\n",
    "        ax.grid(True)\n",
    "\n",
    "    plt.show()\n",
    "    if seq_value is not None:\n",
    "        Path(\"plots\").mkdir(parents=True, exist_ok=True)\n",
    "        Path(f\"plots/{seq_value}\").mkdir(parents=True, exist_ok=True)\n",
    "        # Salvar o gráfico\n",
    "        fig.savefig(f\"plots/{seq_value}/plot-4.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4997ae77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def plot_5(combinacoes_geral, seq_value=None, top_n=15):\n",
    "    label_id_to_name = {\n",
    "        -1: \"plane\",\n",
    "        0: \"unlabeled\",\n",
    "        1: \"car\",\n",
    "        2: \"bicycle\",\n",
    "        3: \"motorcycle\",\n",
    "        4: \"truck\",\n",
    "        5: \"other-vehicle\",\n",
    "        6: \"person\",\n",
    "        7: \"bicyclist\",\n",
    "        8: \"motorcyclist\",\n",
    "        9: \"road\",\n",
    "        10: \"parking\",\n",
    "        11: \"sidewalk\",\n",
    "        12: \"other-ground\",\n",
    "        13: \"building\",\n",
    "        14: \"fence\",\n",
    "        15: \"vegetation\",\n",
    "        16: \"trunk\",\n",
    "        17: \"terrain\",\n",
    "        18: \"pole\",\n",
    "        19: \"traffic-sign\",\n",
    "    }\n",
    "\n",
    "    # total_inconsistentes = sum(combinacoes_geral.values())\n",
    "\n",
    "    # Ordena as combinações do mais frequente para o menos frequente\n",
    "\n",
    "    # for combinacao, count in combinacoes_ordenadas:\n",
    "    #     nomes_labels = [label_id_to_name.get(label, f\"desconhecido({label})\") for label in combinacao]\n",
    "    #     nomes_labels_str = \", \".join(nomes_labels)\n",
    "\n",
    "    #     porcentagem = (count / total_inconsistentes) * 100\n",
    "\n",
    "    combinacoes_ordenadas = sorted(\n",
    "        combinacoes_geral.items(), key=lambda x: x[1], reverse=True\n",
    "    )\n",
    "    # Extrair as combinações e suas contagens\n",
    "    top_combinacoes = combinacoes_ordenadas[:top_n]\n",
    "\n",
    "    # Separar nomes e valores\n",
    "    def formatar_combinacao(combinacao):\n",
    "        nomes = [label_id_to_name.get(int(l), f\"desconhecido({l})\") for l in combinacao]\n",
    "        return \", \".join(nomes)\n",
    "\n",
    "    labels_pizza = [formatar_combinacao(comb) for comb, _ in top_combinacoes]\n",
    "    valores_pizza = [contagem for _, contagem in top_combinacoes]\n",
    "\n",
    "    # Calcular \"outros\"\n",
    "    total = sum(combinacoes_geral.values())\n",
    "    total_top = sum(valores_pizza)\n",
    "    outros = total - total_top\n",
    "\n",
    "    if outros > 0:\n",
    "        labels_pizza.append(\"Outros\")\n",
    "        valores_pizza.append(outros)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    ax.pie(valores_pizza, labels=labels_pizza, autopct=\"%1.1f%%\", startangle=140)\n",
    "    ax.set_title(f\"Top {top_n} combinações inconsistentes + Outros\")\n",
    "    ax.axis(\"equal\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    if seq_value is not None:\n",
    "        Path(\"plots\").mkdir(parents=True, exist_ok=True)\n",
    "        Path(f\"plots/{seq_value}\").mkdir(parents=True, exist_ok=True)\n",
    "        # Salvar o gráfico\n",
    "        fig.savefig(f\"plots/{seq_value}/plot-5.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
