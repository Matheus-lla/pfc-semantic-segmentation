{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e08775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp pointNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5910a68",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e21152f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0148941",
   "metadata": {},
   "source": [
    "# copia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8112a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class TNet(nn.Module):\n",
    "    def __init__(self, k=3):\n",
    "        super(TNet, self).__init__()\n",
    "        self.k = k\n",
    "        # self.conv1 = nn.Conv1d(k, 64, 1)\n",
    "        # self.conv2 = nn.Conv1d(64, 128, 1)\n",
    "        # self.conv3 = nn.Conv1d(128, 1024, 1)\n",
    "        self.conv1 = nn.Conv1d(k, 64, 1)\n",
    "        self.conv1b = nn.Conv1d(64, 128, 1)\n",
    "        self.conv2 = nn.Conv1d(128, 256, 1)\n",
    "        self.conv2b = nn.Conv1d(256, 512, 1)\n",
    "        self.conv3 = nn.Conv1d(512, 1024, 1)\n",
    "        self.conv3b = nn.Conv1d(1024, 2048, 1)\n",
    "\n",
    "        # self.fc1 = nn.Linear(1024, 512)\n",
    "        # self.fc2 = nn.Linear(512, 256)\n",
    "        # self.fc3 = nn.Linear(256, k * k)\n",
    "        self.fc1 = nn.Linear(2048, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.fc4 = nn.Linear(256, k * k)\n",
    "\n",
    "        # self.bn1 = nn.BatchNorm1d(64)\n",
    "        # self.bn2 = nn.BatchNorm1d(128)\n",
    "        # self.bn3 = nn.BatchNorm1d(1024)\n",
    "        # self.bn1 = nn.InstanceNorm1d(64)\n",
    "        # self.bn2 = nn.InstanceNorm1d(128)\n",
    "        # self.bn3 = nn.InstanceNorm1d(1024)\n",
    "        self.bn1 = nn.InstanceNorm1d(64)\n",
    "        self.bn1b = nn.InstanceNorm1d(128)  \n",
    "        self.bn2 = nn.InstanceNorm1d(256)\n",
    "        self.bn2b = nn.InstanceNorm1d(512)\n",
    "        self.bn3 = nn.InstanceNorm1d(1024)\n",
    "        self.bn3b = nn.InstanceNorm1d(2048)\n",
    "\n",
    "        # self.bn4 = nn.BatchNorm1d(512)\n",
    "        # self.bn5 = nn.BatchNorm1d(256)\n",
    "        # self.bn4 = nn.LayerNorm(512)\n",
    "        # self.bn5 = nn.LayerNorm(256)\n",
    "        self.bn4 = nn.LayerNorm(1024)\n",
    "        self.bn5 = nn.LayerNorm(512)\n",
    "        self.bn6 = nn.LayerNorm(256)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, K, N = x.size()\n",
    "        # x = F.relu(self.bn1(self.conv1(x)))\n",
    "        # x = F.relu(self.bn2(self.conv2(x)))\n",
    "        # x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn1b(self.conv1b(x))) \n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn2b(self.conv2b(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = F.relu(self.bn3b(self.conv3b(x))) \n",
    "        x = torch.max(x, 2)[0]\n",
    "        # x = F.relu(self.bn4(self.fc1(x)))\n",
    "        # x = F.relu(self.bn5(self.fc2(x)))\n",
    "\n",
    "        x = F.relu(self.bn4(self.fc1(x)))\n",
    "        x = F.relu(self.bn5(self.fc2(x)))\n",
    "        x = F.relu(self.bn6(self.fc3(x)))\n",
    "        # x = self.fc3(x)\n",
    "        x = self.fc4(x)\n",
    "\n",
    "        iden = torch.eye(self.k, device=x.device).flatten().unsqueeze(0).repeat(B, 1)\n",
    "        x = x + iden\n",
    "        x = x.view(-1, self.k, self.k)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf2904a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class PointNetEncoder(nn.Module):\n",
    "    def __init__(self, global_feat=True, feature_transform=False, channel=9):\n",
    "        super(PointNetEncoder, self).__init__()\n",
    "        self.stn = TNet(k=3)\n",
    "        # self.conv1 = nn.Conv1d(channel, 64, 1)\n",
    "        # self.conv2 = nn.Conv1d(64, 128, 1)\n",
    "        # self.conv3 = nn.Conv1d(128, 1024, 1)\n",
    "        # self.bn1 = nn.InstanceNorm1d(64)\n",
    "        # self.bn2 = nn.InstanceNorm1d(128)\n",
    "        # self.bn3 = nn.InstanceNorm1d(1024)\n",
    "        self.conv1 = nn.Conv1d(channel, 64, 1)\n",
    "        self.conv1b = nn.Conv1d(64, 128, 1)  # Nova camada\n",
    "        self.conv2 = nn.Conv1d(128, 256, 1)  # Dobrado: 64->128, 128->256\n",
    "        self.conv2b = nn.Conv1d(256, 512, 1)  # Nova camada\n",
    "        self.conv3 = nn.Conv1d(512, 1024, 1)  # Dobrado: 128->256, 256->512\n",
    "        self.conv3b = nn.Conv1d(1024, 2048, 1)  # Nova camada + dobrado: 1024->2048\n",
    "\n",
    "        self.bn1 = nn.InstanceNorm1d(64)\n",
    "        self.bn1b = nn.InstanceNorm1d(128)  # Para nova camada\n",
    "        self.bn2 = nn.InstanceNorm1d(256)  # Dobrado\n",
    "        self.bn2b = nn.InstanceNorm1d(512)  # Para nova camada\n",
    "        self.bn3 = nn.InstanceNorm1d(1024)  # Original\n",
    "        self.bn3b = nn.InstanceNorm1d(2048)  # Para nova camada\n",
    "\n",
    "        self.global_feat = global_feat\n",
    "        self.feature_transform = feature_transform\n",
    "        if self.feature_transform:\n",
    "            # self.fstn = TNet(k=64)\n",
    "            self.fstn = TNet(k=128)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, N = x.size()\n",
    "        # Input transform only on first 3 dims (xyz)\n",
    "        trans = self.stn(x[:, :3, :])\n",
    "        x_xyz = x[:, :3, :]\n",
    "        x_rest = x[:, 3:, :] if C > 3 else None\n",
    "        x_xyz = torch.bmm(trans, x_xyz)\n",
    "        if x_rest is not None:\n",
    "            x = torch.cat([x_xyz, x_rest], dim=1)\n",
    "        else:\n",
    "            x = x_xyz\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn1b(self.conv1b(x)))    # Nova camada\n",
    "\n",
    "        if self.feature_transform:\n",
    "            trans_feat = self.fstn(x)\n",
    "            x = torch.bmm(trans_feat, x)\n",
    "        else:\n",
    "            trans_feat = None\n",
    "\n",
    "        pointfeat = x  # pointfeat agora tem 128 canais\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn2b(self.conv2b(x)))  # Nova camada\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.bn3b(self.conv3b(x))  # Nova camada\n",
    "        x = torch.max(x, 2, keepdim=True)[0]\n",
    "        # x = x.view(-1, 1024)\n",
    "        x = x.view(-1, 2048)                    # Dobrado: 1024->2048\n",
    "        if self.global_feat:\n",
    "            return x, trans, trans_feat\n",
    "        else:\n",
    "            # x = x.view(-1, 1024, 1).repeat(1, 1, N)\n",
    "            x = x.view(-1, 2048, 1).repeat(1, 1, N)  # Dobrado: 1024->2048\n",
    "            return torch.cat([x, pointfeat], 1), trans, trans_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a522367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class PointNetSeg(nn.Module):\n",
    "    def __init__(self, num_classes, input_channels=9, feature_transform=True):\n",
    "        super(PointNetSeg, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.feat = PointNetEncoder(\n",
    "            global_feat=False,\n",
    "            feature_transform=feature_transform,\n",
    "            channel=input_channels,\n",
    "        )\n",
    "        # self.conv1 = nn.Conv1d(1088, 512, 1)\n",
    "        # self.conv2 = nn.Conv1d(512, 256, 1)\n",
    "        # self.conv3 = nn.Conv1d(256, 128, 1)\n",
    "        # self.conv4 = nn.Conv1d(128, self.num_classes, 1)\n",
    "        # self.bn1 = nn.InstanceNorm1d(512)\n",
    "        # self.bn2 = nn.InstanceNorm1d(256)\n",
    "        # self.bn3 = nn.InstanceNorm1d(128)\n",
    "        # A dimensão de entrada agora é 2048 (global) + 128 (pointfeat) = 2176\n",
    "        self.conv1 = nn.Conv1d(2176, 1024, 1) # Adaptado para nova dimensão: 1088->2176, 512->1024\n",
    "        self.conv1b = nn.Conv1d(1024, 768, 1) # Nova camada\n",
    "        self.conv2 = nn.Conv1d(768, 512, 1)  # Dobrado: 256->512\n",
    "        self.conv2b = nn.Conv1d(512, 384, 1)  # Nova camada\n",
    "        self.conv3 = nn.Conv1d(384, 256, 1)  # Dobrado: 128->256\n",
    "        self.conv3b = nn.Conv1d(256, 192, 1)  # Nova camada\n",
    "        self.conv4 = nn.Conv1d(192, self.num_classes, 1)  # Última camada\n",
    "\n",
    "        self.bn1 = nn.InstanceNorm1d(1024)\n",
    "        self.bn1b = nn.InstanceNorm1d(768)  # Para nova camada\n",
    "        self.bn2 = nn.InstanceNorm1d(512)\n",
    "        self.bn2b = nn.InstanceNorm1d(384)  # Para nova camada\n",
    "        self.bn3 = nn.InstanceNorm1d(256)\n",
    "        self.bn3b = nn.InstanceNorm1d(192)  # Para nova camada\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Espera entrada: (B, N, C) -> (B, C, N)\n",
    "        x = x.transpose(1, 2)  # (B, C, N)\n",
    "        # if x.shape[1] < x.shape[2]:\n",
    "        #     x = x.transpose(1, 2)  # (B, C, N)\n",
    "\n",
    "        batchsize = x.size()[0]\n",
    "        n_pts = x.size()[2]\n",
    "        x, trans, trans_feat = self.feat(x)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn1b(self.conv1b(x)))  # Nova camada\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn2b(self.conv2b(x)))  # Nova camada\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = F.relu(self.bn3b(self.conv3b(x)))  # Nova camada\n",
    "        x = self.conv4(x)\n",
    "        x = x.transpose(2, 1).contiguous()  # (B, N, num_classes)\n",
    "        # falta aplicar softmax e view do codigo copiado\n",
    "        return x, trans_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de119f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def feature_transform_regulaizer(trans):\n",
    "    d = trans.size()[1]\n",
    "    I = torch.eye(d, device=trans.device)[None, :, :]\n",
    "    loss = torch.mean(\n",
    "        torch.norm(torch.bmm(trans, trans.transpose(2, 1)) - I, dim=(1, 2))\n",
    "    )\n",
    "    return loss"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
