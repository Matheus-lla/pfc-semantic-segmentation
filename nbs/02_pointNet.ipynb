{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e08775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp pointNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5910a68",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e21152f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a865c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TNet(nn.Module):\n",
    "    def __init__(self, k=3):\n",
    "        super(TNet, self).__init__()\n",
    "        self.k = k\n",
    "        self.conv1 = nn.Conv1d(k, 64, 1)\n",
    "        self.conv2 = nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = nn.Conv1d(128, 1024, 1)\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, k * k)\n",
    "\n",
    "        self.bn1 = nn.InstanceNorm1d(64, affine=True)\n",
    "        self.bn2 = nn.InstanceNorm1d(128, affine=True)\n",
    "        self.bn3 = nn.InstanceNorm1d(1024, affine=True)\n",
    "        self.bn4 = nn.Identity()\n",
    "        self.bn5 = nn.Identity()\n",
    "        # self.bn4 = nn.InstanceNorm1d(512, affine=True)\n",
    "        # self.bn5 = nn.InstanceNorm1d(256, affine=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, K, N = x.size()\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = torch.max(x, 2)[0]\n",
    "        x = F.relu(self.bn4(self.fc1(x)))\n",
    "        x = F.relu(self.bn5(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        iden = torch.eye(self.k).flatten().to(x.device)\n",
    "        x = x + iden\n",
    "        x = x.view(-1, self.k, self.k)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3182bc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointNetSeg(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(PointNetSeg, self).__init__()\n",
    "        self.input_transform = TNet(k=3)\n",
    "\n",
    "        self.conv1 = nn.Conv1d(input_size, 64, 1)\n",
    "        self.conv2 = nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = nn.Conv1d(128, 1024, 1)\n",
    "\n",
    "        self.bn1 = nn.InstanceNorm1d(64, affine=True)\n",
    "        self.bn2 = nn.InstanceNorm1d(128, affine=True)\n",
    "        self.bn3 = nn.InstanceNorm1d(1024, affine=True)\n",
    "\n",
    "        self.fc1 = nn.Conv1d(1088, 512, 1)\n",
    "        self.fc2 = nn.Conv1d(512, 256, 1)\n",
    "        self.fc3 = nn.Conv1d(256, num_classes, 1)\n",
    "\n",
    "        self.bn4 = nn.InstanceNorm1d(512)\n",
    "        self.bn5 = nn.InstanceNorm1d(256)\n",
    "\n",
    "        # self.dropout = nn.Dropout(p=0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, N, _ = x.size()\n",
    "        x = x.transpose(2, 1)  # B x 3 x N\n",
    "\n",
    "        trans = self.input_transform(x)\n",
    "        x = torch.bmm(trans, x)\n",
    "\n",
    "        x = F.relu(self.bn1(self.conv1(x)))  # B x 64 x N\n",
    "        x1 = x\n",
    "        x = F.relu(self.bn2(self.conv2(x)))  # B x 128 x N\n",
    "        x = F.relu(self.bn3(self.conv3(x)))  # B x 1024 x N\n",
    "\n",
    "        x = torch.max(x, 2, keepdim=True)[0]  # B x 1024 x 1\n",
    "        x = x.repeat(1, 1, N)  # B x 1024 x N\n",
    "\n",
    "        x = torch.cat([x1, x], 1)  # B x 1088 x N\n",
    "\n",
    "        x = F.relu(self.bn4(self.fc1(x)))  # B x 512 x N\n",
    "        # x = F.relu(self.bn5(self.dropout(self.fc2(x))))  # B x 256 x N\n",
    "        x = F.relu(self.bn5(self.fc2(x)))  # B x 256 x N\n",
    "        x = self.fc3(x)  # B x num_classes x N\n",
    "\n",
    "        x = x.transpose(2, 1).contiguous()  # B x N x num_classes\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0148941",
   "metadata": {},
   "source": [
    "# copia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8112a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class TNet(nn.Module):\n",
    "    def __init__(self, k=3):\n",
    "        super(TNet, self).__init__()\n",
    "        self.k = k\n",
    "        self.conv1 = nn.Conv1d(k, 64, 1)\n",
    "        self.conv2 = nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = nn.Conv1d(128, 1024, 1)\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, k * k)\n",
    "\n",
    "        # self.bn1 = nn.BatchNorm1d(64)\n",
    "        # self.bn2 = nn.BatchNorm1d(128)\n",
    "        # self.bn3 = nn.BatchNorm1d(1024)\n",
    "        self.bn1 = nn.InstanceNorm1d(64)\n",
    "        self.bn2 = nn.InstanceNorm1d(128)\n",
    "        self.bn3 = nn.InstanceNorm1d(1024)\n",
    "        # self.bn4 = nn.BatchNorm1d(512)\n",
    "        # self.bn5 = nn.BatchNorm1d(256)\n",
    "        self.bn4 = nn.LayerNorm(512)\n",
    "        self.bn5 = nn.LayerNorm(256)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, K, N = x.size()\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = torch.max(x, 2)[0]\n",
    "        x = F.relu(self.bn4(self.fc1(x)))\n",
    "        x = F.relu(self.bn5(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        iden = torch.eye(self.k, device=x.device).flatten().unsqueeze(0).repeat(B, 1)\n",
    "        x = x + iden\n",
    "        x = x.view(-1, self.k, self.k)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf2904a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class PointNetEncoder(nn.Module):\n",
    "    def __init__(self, global_feat=True, feature_transform=False, channel=9):\n",
    "        super(PointNetEncoder, self).__init__()\n",
    "        self.stn = TNet(k=3)\n",
    "        self.conv1 = nn.Conv1d(channel, 64, 1)\n",
    "        self.conv2 = nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = nn.Conv1d(128, 1024, 1)\n",
    "        self.bn1 = nn.InstanceNorm1d(64)\n",
    "        self.bn2 = nn.InstanceNorm1d(128)\n",
    "        self.bn3 = nn.InstanceNorm1d(1024)\n",
    "        self.global_feat = global_feat\n",
    "        self.feature_transform = feature_transform\n",
    "        if self.feature_transform:\n",
    "            self.fstn = TNet(k=64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, N = x.size()\n",
    "        # Input transform only on first 3 dims (xyz)\n",
    "        trans = self.stn(x[:, :3, :])\n",
    "        x_xyz = x[:, :3, :]\n",
    "        x_rest = x[:, 3:, :] if C > 3 else None\n",
    "        x_xyz = torch.bmm(trans, x_xyz)\n",
    "        if x_rest is not None:\n",
    "            x = torch.cat([x_xyz, x_rest], dim=1)\n",
    "        else:\n",
    "            x = x_xyz\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "\n",
    "        if self.feature_transform:\n",
    "            trans_feat = self.fstn(x)\n",
    "            x = torch.bmm(trans_feat, x)\n",
    "        else:\n",
    "            trans_feat = None\n",
    "\n",
    "        pointfeat = x\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.bn3(self.conv3(x))\n",
    "        x = torch.max(x, 2, keepdim=True)[0]\n",
    "        x = x.view(-1, 1024)\n",
    "        if self.global_feat:\n",
    "            return x, trans, trans_feat\n",
    "        else:\n",
    "            x = x.view(-1, 1024, 1).repeat(1, 1, N)\n",
    "            return torch.cat([x, pointfeat], 1), trans, trans_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a522367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class PointNetSeg(nn.Module):\n",
    "    def __init__(self, num_classes, input_channels=9, feature_transform=True):\n",
    "        super(PointNetSeg, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.feat = PointNetEncoder(\n",
    "            global_feat=False,\n",
    "            feature_transform=feature_transform,\n",
    "            channel=input_channels,\n",
    "        )\n",
    "        self.conv1 = nn.Conv1d(1088, 512, 1)\n",
    "        self.conv2 = nn.Conv1d(512, 256, 1)\n",
    "        self.conv3 = nn.Conv1d(256, 128, 1)\n",
    "        self.conv4 = nn.Conv1d(128, self.num_classes, 1)\n",
    "        self.bn1 = nn.InstanceNorm1d(512)\n",
    "        self.bn2 = nn.InstanceNorm1d(256)\n",
    "        self.bn3 = nn.InstanceNorm1d(128)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Espera entrada: (B, N, C) -> (B, C, N)\n",
    "        x = x.transpose(1, 2)  # (B, C, N)\n",
    "        # if x.shape[1] < x.shape[2]:\n",
    "        #     x = x.transpose(1, 2)  # (B, C, N)\n",
    "\n",
    "        batchsize = x.size()[0]\n",
    "        n_pts = x.size()[2]\n",
    "        x, trans, trans_feat = self.feat(x)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.conv4(x)\n",
    "        x = x.transpose(2, 1).contiguous()  # (B, N, num_classes)\n",
    "        # falta aplicar softmax e view do codigo copiado\n",
    "        return x, trans_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de119f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def feature_transform_regulaizer(trans):\n",
    "    d = trans.size()[1]\n",
    "    I = torch.eye(d, device=trans.device)[None, :, :]\n",
    "    loss = torch.mean(\n",
    "        torch.norm(torch.bmm(trans, trans.transpose(2, 1)) - I, dim=(1, 2))\n",
    "    )\n",
    "    return loss"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
