{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa027742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4aa6afb",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec7d72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "import sys\n",
    "import threading\n",
    "from collections import Counter, defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from torch.utils import data\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8-whitegrid\")  # ou \"ggplot\", \"seaborn-paper\", etc.\n",
    "\n",
    "plt.rcParams.update(\n",
    "    {\n",
    "        \"font.size\": 16,\n",
    "        \"axes.titlesize\": 20,\n",
    "        \"axes.labelsize\": 18,\n",
    "        \"legend.fontsize\": 14,\n",
    "        \"xtick.labelsize\": 14,\n",
    "        \"ytick.labelsize\": 14,\n",
    "        \"font.family\": \"serif\",  # ou \"Times New Roman\"\n",
    "    }\n",
    ")\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990b8ca9",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b62e0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class Dataset(data.Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_path: str,\n",
    "        split: str = \"train\",\n",
    "        load_cluster: bool = False,\n",
    "        return_np_array: bool = True,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Initialize dataset loader.\n",
    "\n",
    "        Args:\n",
    "            data_path (str or Path): Base path to the SemanticKITTI dataset.\n",
    "            split (str): Dataset split to use ('train', 'valid', or 'test').\n",
    "        \"\"\"\n",
    "        self.data_path: Path = Path(data_path)\n",
    "        self.split: str = split\n",
    "        self.is_test: bool = split == \"test\"\n",
    "        self.load_cluster: bool = load_cluster\n",
    "        self.return_np_array = return_np_array\n",
    "\n",
    "        # Paths to YAML config and data folders\n",
    "        self.yaml_path: Path = Path(\"../tests/semantic-kitti.yaml\")\n",
    "        # self.yaml_path: Path = self.data_path / 'semantic-kitti.yaml'\n",
    "        self.velodynes_path: Path = (\n",
    "            self.data_path / \"data_odometry_velodyne/dataset/sequences\"\n",
    "        )\n",
    "        self.labels_path: Path = (\n",
    "            self.data_path / \"data_odometry_labels/dataset/sequences\"\n",
    "        )\n",
    "        self.clusters_path: Path = (\n",
    "            self.data_path / \"data_odometry_clusters/dataset/sequences\"\n",
    "        )\n",
    "\n",
    "        # Load dataset metadata and label mappings\n",
    "        with open(self.yaml_path, \"r\") as file:\n",
    "            metadata: dict = yaml.safe_load(file)\n",
    "\n",
    "        self.sequences: list[int] = metadata[\"split\"][split]\n",
    "        self.learning_map: dict[int, int] = metadata[\"learning_map\"]\n",
    "\n",
    "        # Convert label map to numpy for fast lookup\n",
    "        max_label: int = max(self.learning_map.keys())\n",
    "        self.learning_map_np: np.ndarray = np.zeros((max_label + 1,), dtype=np.uint32)\n",
    "        for raw_label, mapped_label in self.learning_map.items():\n",
    "            self.learning_map_np[raw_label] = mapped_label\n",
    "\n",
    "        # Collect all frame paths for selected sequences\n",
    "        self.frame_paths: list[tuple[str, str]] = self._collect_frame_paths()\n",
    "\n",
    "        self.last_seq = None\n",
    "        self.last_frame_id = None\n",
    "\n",
    "    def _collect_frame_paths(self) -> \"list[tuple[str, str]]\":\n",
    "        \"\"\"Collect all (sequence, frame_id) pairs from the dataset split.\"\"\"\n",
    "        frame_list = []\n",
    "        for seq in self.sequences:\n",
    "            seq_str = f\"{int(seq):02d}\"\n",
    "            seq_velo_path = self.velodynes_path / seq_str / \"velodyne\"\n",
    "            velo_files = sorted(seq_velo_path.glob(\"*.bin\"))\n",
    "            for file in velo_files:\n",
    "                frame_list.append((seq_str, file.stem))\n",
    "        return frame_list\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"Return number of samples in the dataset split.\"\"\"\n",
    "        return len(self.frame_paths)\n",
    "\n",
    "    def __iter__(self):\n",
    "        self._iter_idx = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self._iter_idx < len(self):\n",
    "            item = self[self._iter_idx]\n",
    "            self._iter_idx += 1\n",
    "            return item\n",
    "        else:\n",
    "            raise StopIteration\n",
    "\n",
    "    def _compute_scanline_ids(\n",
    "        self, point_cloud: np.ndarray, n_scans: int = 64\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Approximate scanline indices based on point order.\n",
    "\n",
    "        Args:\n",
    "            point_cloud (np.ndarray): Nx3 array of 3D points.\n",
    "            n_scans (int): Number of LiDAR scanlines (e.g., 64 for HDL-64E).\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: Nx1 array with estimated scanline indices (0 to n_scans - 1).\n",
    "        \"\"\"\n",
    "        total_points = point_cloud.shape[0]\n",
    "        scanline_ids = np.floor(\n",
    "            np.linspace(0, n_scans, total_points, endpoint=False)\n",
    "        ).astype(int)\n",
    "        return scanline_ids.reshape(-1, 1)\n",
    "\n",
    "    def get_last_seq_frame(self) -> tuple[str, str] | None:\n",
    "        \"\"\"\n",
    "        Get the last sequence and frame ID loaded.\n",
    "\n",
    "        Returns:\n",
    "            tuple: (sequence, frame_id)\n",
    "        \"\"\"\n",
    "\n",
    "        if self.last_seq is None or self.last_frame_id is None:\n",
    "            return None\n",
    "        else:\n",
    "            return self.last_seq, self.last_frame_id\n",
    "\n",
    "    def __getitem__(self, idx: int) -> \"dict[str, np.ndarray] | np.ndarray\":\n",
    "        \"\"\"\n",
    "        Load a sample from the dataset.\n",
    "\n",
    "        Args:\n",
    "            idx (int): Index of the frame to load.\n",
    "\n",
    "        Returns:\n",
    "            tuple:\n",
    "                - point_cloud_with_label (np.ndarray): Nx6 array [x, y, z, true_label, pred_label, scanline_id].\n",
    "                - item_dict (dict): Contains 'point_cloud', 'label', and 'mask'.\n",
    "        \"\"\"\n",
    "\n",
    "        seq, frame_id = self.frame_paths[idx]\n",
    "        self.last_seq = seq\n",
    "        self.last_frame_id = frame_id\n",
    "\n",
    "        # Load point cloud (Nx4), drop reflectance\n",
    "        velodyne_file_path = self.velodynes_path / seq / \"velodyne\" / f\"{frame_id}.bin\"\n",
    "        with open(velodyne_file_path, \"rb\") as file:\n",
    "            point_cloud = np.fromfile(file, dtype=np.float32).reshape(-1, 4)[:, :3]\n",
    "\n",
    "        # Load and map semantic labels\n",
    "        if not self.is_test:\n",
    "            label_file_path = self.labels_path / seq / \"labels\" / f\"{frame_id}.label\"\n",
    "            if label_file_path.exists():\n",
    "                with open(label_file_path, \"rb\") as file:\n",
    "                    raw_labels = np.fromfile(file, dtype=np.uint32) & 0xFFFF\n",
    "                labels = self.learning_map_np[raw_labels]\n",
    "                mask = labels != 0\n",
    "            else:\n",
    "                labels = np.zeros(point_cloud.shape[0], dtype=np.uint32)\n",
    "                mask = np.ones(point_cloud.shape[0], dtype=bool)\n",
    "        else:\n",
    "            labels = np.zeros(point_cloud.shape[0], dtype=np.uint32)\n",
    "            mask = np.ones(point_cloud.shape[0], dtype=bool)\n",
    "\n",
    "        # Estimate scanline indices\n",
    "        scanline_ids = self._compute_scanline_ids(point_cloud)\n",
    "\n",
    "        if self.load_cluster:\n",
    "            cluster_file_path = (\n",
    "                self.clusters_path / seq / \"clusters\" / f\"{frame_id}_cluster.label\"\n",
    "            )\n",
    "            if cluster_file_path.exists():\n",
    "                with open(cluster_file_path, \"rb\") as file:\n",
    "                    clusters = np.fromfile(file, dtype=np.uint32)\n",
    "                if clusters.shape[0] != point_cloud.shape[0]:\n",
    "                    raise ValueError(\n",
    "                        f\"Predicted label count mismatch for frame {seq}/{frame_id}\"\n",
    "                    )\n",
    "                clusters = clusters.reshape(-1, 1)\n",
    "            else:\n",
    "                clusters = np.zeros((point_cloud.shape[0], 1), dtype=np.uint32)\n",
    "        else:\n",
    "            clusters = np.zeros((point_cloud.shape[0], 1), dtype=np.uint32)\n",
    "\n",
    "        # # Final format: [x, y, z, true_label, predicted_label, scanline_id]\n",
    "        point_cloud_array = np.hstack(\n",
    "            (point_cloud, labels.reshape(-1, 1), clusters, scanline_ids)\n",
    "        )\n",
    "\n",
    "        item_dict = {\n",
    "            \"point_cloud\": point_cloud,\n",
    "            \"label\": labels,\n",
    "            \"cluster\": clusters,\n",
    "            \"scanline_id\": scanline_ids,\n",
    "            \"mask\": mask,\n",
    "        }\n",
    "\n",
    "        if self.return_np_array:\n",
    "            return point_cloud_array\n",
    "        else:\n",
    "            return item_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52091605",
   "metadata": {},
   "source": [
    "# Visualizer for Point Clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb63aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class PointCloudVisualizer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        point_size: float = 1.0,\n",
    "        grid_size=50,\n",
    "        grid_spacing=1.0,\n",
    "        grid_line_width=10,\n",
    "        cluster_viz=False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Visualizer class for rendering point clouds using Open3D with color-coded semantic labels.\n",
    "\n",
    "        Args:\n",
    "            point_size (float): Default size of points in the Open3D viewer.\n",
    "        \"\"\"\n",
    "        self.point_size = point_size\n",
    "        self.fixed_colors_rgb = self._get_fixed_colors_rgb()\n",
    "        self.grid_size = grid_size\n",
    "        self.grid_spacing = grid_spacing\n",
    "        self.grid_line_width = grid_line_width\n",
    "        self.cluster_viz = cluster_viz\n",
    "\n",
    "    def set_point_sieze(self, point_size):\n",
    "        self.point_size = point_size\n",
    "\n",
    "    def set_grid_size(self, grid_size):\n",
    "        self.grid_size = grid_size\n",
    "\n",
    "    def set_grid_spacing(self, grid_spacing):\n",
    "        self.grid_spacing = grid_spacing\n",
    "\n",
    "    def set_grid_line_width(self, grid_line_width):\n",
    "        self.grid_line_width = grid_line_width\n",
    "\n",
    "    def _get_fixed_colors_rgb(self) -> \"dict[int, list[float]]\":\n",
    "        fixed_colors = {\n",
    "            -1: [255, 255, 255],  # plane\n",
    "            0: [0, 0, 0],  # unlabeled\n",
    "            1: [245, 150, 100],  # car\n",
    "            2: [245, 230, 100],  # bicycle\n",
    "            3: [150, 60, 30],  # motorcycle\n",
    "            4: [180, 30, 80],  # truck\n",
    "            5: [250, 80, 100],  # other-vehicle\n",
    "            6: [30, 30, 255],  # person\n",
    "            7: [200, 40, 255],  # bicyclist\n",
    "            8: [90, 30, 150],  # motorcyclist\n",
    "            9: [255, 0, 255],  # road\n",
    "            10: [255, 150, 255],  # parking\n",
    "            11: [75, 0, 75],  # sidewalk\n",
    "            12: [75, 0, 175],  # other-ground\n",
    "            13: [0, 200, 255],  # building\n",
    "            14: [50, 120, 255],  # fence\n",
    "            15: [0, 175, 0],  # vegetation\n",
    "            16: [0, 60, 135],  # trunk\n",
    "            17: [80, 240, 150],  # terrain\n",
    "            18: [150, 240, 255],  # pole\n",
    "            19: [0, 0, 255],  # traffic-sign\n",
    "        }\n",
    "        return {\n",
    "            label: [c / 255.0 for c in reversed(rgb)]\n",
    "            for label, rgb in fixed_colors.items()\n",
    "        }\n",
    "\n",
    "    def _get_color_map(self, labels: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Assigns RGB colors to labels.\n",
    "\n",
    "        Args:\n",
    "            labels (np.ndarray): Array of label ids.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: Nx3 array of RGB colors.\n",
    "        \"\"\"\n",
    "        color_map = np.zeros((labels.shape[0], 3))\n",
    "        for i, label in enumerate(labels):\n",
    "            if label in self.fixed_colors_rgb:\n",
    "                color_map[i] = self.fixed_colors_rgb[label]\n",
    "            else:\n",
    "                rng = np.random.default_rng(label)\n",
    "                color_map[i] = rng.random(3)\n",
    "        return color_map\n",
    "\n",
    "    def _create_grid(self, grid_size=50, grid_spacing=1.0):\n",
    "        points = []\n",
    "        lines = []\n",
    "        colors = []\n",
    "\n",
    "        for i in range(-grid_size, grid_size + 1):\n",
    "            # Linhas paralelas ao eixo X\n",
    "            points.append([i * grid_spacing, -grid_size * grid_spacing, 0])\n",
    "            points.append([i * grid_spacing, grid_size * grid_spacing, 0])\n",
    "            lines.append([len(points) - 2, len(points) - 1])\n",
    "\n",
    "            # Linhas paralelas ao eixo Y\n",
    "            points.append([-grid_size * grid_spacing, i * grid_spacing, 0])\n",
    "            points.append([grid_size * grid_spacing, i * grid_spacing, 0])\n",
    "            lines.append([len(points) - 2, len(points) - 1])\n",
    "\n",
    "            # Cores: mais clara a cada 10 unidades\n",
    "            color = [0.3, 0.3, 0.3] if i % 10 else [0.6, 0.6, 0.6]\n",
    "            colors.extend([color, color])\n",
    "\n",
    "        grid = o3d.geometry.LineSet()\n",
    "        grid.points = o3d.utility.Vector3dVector(points)\n",
    "        grid.lines = o3d.utility.Vector2iVector(lines)\n",
    "        grid.colors = o3d.utility.Vector3dVector(colors)\n",
    "        return grid\n",
    "\n",
    "    def _create_plane(self, normal_d_tuple, size=100.0):\n",
    "        \"\"\"\n",
    "        Cria um plano baseado no vetor normal e no valor d.\n",
    "\n",
    "        Args:\n",
    "            normal_d_tuple (tuple): Tuple contendo o vetor normal (x, y, z) e o valor d.\n",
    "            size (float): Tamanho do plano a ser desenhado.\n",
    "\n",
    "        Returns:\n",
    "            o3d.geometry.TriangleMesh: Mesh do plano.\n",
    "        \"\"\"\n",
    "        normal, d = normal_d_tuple\n",
    "\n",
    "        # Normalizar o vetor normal\n",
    "        normal = np.array(normal)\n",
    "        normal = normal / np.linalg.norm(normal)\n",
    "\n",
    "        # Calcular 4 pontos do plano\n",
    "        p1 = np.array(\n",
    "            [-size, -size, -(normal[0] * (-size) + normal[1] * (-size) + d) / normal[2]]\n",
    "        )\n",
    "        p2 = np.array(\n",
    "            [size, -size, -(normal[0] * size + normal[1] * (-size) + d) / normal[2]]\n",
    "        )\n",
    "        p3 = np.array(\n",
    "            [size, size, -(normal[0] * size + normal[1] * size + d) / normal[2]]\n",
    "        )\n",
    "        p4 = np.array(\n",
    "            [-size, size, -(normal[0] * (-size) + normal[1] * size + d) / normal[2]]\n",
    "        )\n",
    "\n",
    "        # Criar os pontos para o mesh\n",
    "        points = np.vstack((p1, p2, p3, p4))\n",
    "\n",
    "        # Criar os triângulos que formam o plano\n",
    "        triangles = [[0, 1, 2], [0, 2, 3]]  # Triângulo 1  # Triângulo 2\n",
    "\n",
    "        # Criar a malha triangular\n",
    "        plane_mesh = o3d.geometry.TriangleMesh()\n",
    "        plane_mesh.vertices = o3d.utility.Vector3dVector(points)\n",
    "        plane_mesh.triangles = o3d.utility.Vector3iVector(triangles)\n",
    "\n",
    "        # Colorir a malha do plano de azul\n",
    "        plane_mesh.paint_uniform_color([0.45, 0.45, 0.45])\n",
    "\n",
    "        return plane_mesh\n",
    "\n",
    "    def _create_axis_arrow(self, length=1.0, color=[1, 0, 0], rotation=None):\n",
    "        arrow = o3d.geometry.TriangleMesh.create_arrow(\n",
    "            cylinder_radius=0.01,\n",
    "            cone_radius=0.03,\n",
    "            cylinder_height=length * 0.8,\n",
    "            cone_height=length * 0.2,\n",
    "        )\n",
    "        arrow.compute_vertex_normals()\n",
    "        arrow.paint_uniform_color(color)\n",
    "        if rotation is not None:\n",
    "            arrow.rotate(rotation, center=(0, 0, 0))\n",
    "        return arrow\n",
    "\n",
    "    def show(self, *args, **kwargs):\n",
    "        if self.cluster_viz:\n",
    "            self.show_clusters(*args, **kwargs)\n",
    "        else:\n",
    "            self.show_point_cloud(*args, **kwargs)\n",
    "\n",
    "    def show_clusters(\n",
    "        self,\n",
    "        clusters: np.ndarray,\n",
    "        show_true_label: bool = False,\n",
    "        show_grid: bool = False,\n",
    "    ) -> None:\n",
    "        pass\n",
    "\n",
    "    def show_point_cloud(\n",
    "        self,\n",
    "        point_cloud: np.ndarray,\n",
    "        normal_d_tuple: tuple | None = None,\n",
    "        show_true_label: bool = False,\n",
    "        show_ground: bool = True,\n",
    "        show_clusters: bool = True,\n",
    "        show_unlabeled: bool = True,\n",
    "        show_plane: bool = False,\n",
    "        show_grid: bool = False,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Visualize the filtered point cloud using Open3D.\n",
    "\n",
    "        Args:\n",
    "            point_cloud (np.ndarray): N x 6 array [x, y, z, true_label, pred_label, scanline_id].\n",
    "        \"\"\"\n",
    "\n",
    "        label_col = 3 if show_true_label else 4\n",
    "        labels = point_cloud[:, label_col]\n",
    "\n",
    "        # Apply filter mask\n",
    "        mask = (\n",
    "            (show_plane & (labels == -1))\n",
    "            | (show_unlabeled & (labels == 0))\n",
    "            | (show_ground & (labels == 9))\n",
    "            | (show_clusters & (labels >= 1) & (labels != 9))\n",
    "        )\n",
    "\n",
    "        xyz = point_cloud[mask, :3]\n",
    "        visible_labels = labels[mask].astype(int)\n",
    "        colors = self._get_color_map(visible_labels)\n",
    "\n",
    "        # Visualize with point size\n",
    "        vis = o3d.visualization.Visualizer()  # type: ignore\n",
    "        vis.create_window(window_name=\"Plane Visualization\", width=800, height=600)\n",
    "\n",
    "        opt = vis.get_render_option()\n",
    "        opt.point_size = self.point_size\n",
    "        opt.background_color = np.asarray([0.1, 0.1, 0.1])  # estilo AutoCAD / pptk\n",
    "        opt.show_coordinate_frame = True\n",
    "        opt.mesh_show_back_face = True  # Exibir o lado de trás do plano\n",
    "\n",
    "        # extrair para uma funcao\n",
    "        # X (vermelho): rotaciona -90° ao redor Z\n",
    "        arrow_x = self._create_axis_arrow(\n",
    "            length=1.0,\n",
    "            color=[1, 0, 0],\n",
    "            rotation=o3d.geometry.get_rotation_matrix_from_xyz([0, np.pi / 2, 0]),\n",
    "        )\n",
    "        # Y (verde): rotaciona +90° ao redor X\n",
    "        arrow_y = self._create_axis_arrow(\n",
    "            length=1.0,\n",
    "            color=[0, 1, 0],\n",
    "            rotation=o3d.geometry.get_rotation_matrix_from_xyz([-np.pi / 2, 0, 0]),\n",
    "        )\n",
    "        # Z (azul): já está na direção Z por padrão\n",
    "        arrow_z = self._create_axis_arrow(length=1.0, color=[0, 0, 1], rotation=None)\n",
    "        vis.add_geometry(arrow_x)\n",
    "        vis.add_geometry(arrow_y)\n",
    "        vis.add_geometry(arrow_z)\n",
    "\n",
    "        # Create Open3D point cloud\n",
    "        pcd = o3d.geometry.PointCloud()\n",
    "        pcd.points = o3d.utility.Vector3dVector(xyz)\n",
    "        pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "        vis.add_geometry(pcd)\n",
    "\n",
    "        if show_grid:\n",
    "            vis.add_geometry(\n",
    "                self._create_grid(self.grid_size, self.grid_spacing)\n",
    "            )  # grid grande com espaçamento 1m\n",
    "            opt.line_width = self.grid_line_width\n",
    "        if show_plane and normal_d_tuple != None:\n",
    "            vis.add_geometry(self._create_plane(normal_d_tuple))\n",
    "\n",
    "        vis.run()\n",
    "        vis.destroy_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c68ebcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def run_viz(point_cloud, normal_d_tuple=None, **visualizer_params):\n",
    "    temp_dir = \"temp_vis\"\n",
    "    os.makedirs(temp_dir, exist_ok=True)\n",
    "\n",
    "    # Salvar nuvem de pontos\n",
    "    np.save(os.path.join(temp_dir, \"point_cloud.npy\"), point_cloud)\n",
    "\n",
    "    # Salvar plano (normal + d)\n",
    "    if normal_d_tuple:\n",
    "        normal_d = np.array([*normal_d_tuple[0], normal_d_tuple[1]])\n",
    "        np.save(os.path.join(temp_dir, \"normal_d.npy\"), normal_d)\n",
    "\n",
    "    # Salvar parâmetros\n",
    "    with open(os.path.join(temp_dir, \"visualizer_config.json\"), \"w\") as f:\n",
    "        json.dump(visualizer_params, f)\n",
    "\n",
    "    # Rodar visualizador em subprocesso chamando o próprio utils.py\n",
    "    comando = [\"python3\", \"../pfc_packages/utils.py\", temp_dir]\n",
    "    thread = threading.Thread(target=lambda: subprocess.run(comando))\n",
    "    thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4132bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def main_viz(temp_dir):\n",
    "    # Carrega dados salvos no diretório temporário\n",
    "    point_cloud = np.load(os.path.join(temp_dir, \"point_cloud.npy\"))\n",
    "\n",
    "    normal_d_path = os.path.join(temp_dir, \"normal_d.npy\")\n",
    "    if os.path.exists(normal_d_path):\n",
    "        normal_d_arr = np.load(normal_d_path)\n",
    "        normal_d_tuple = (normal_d_arr[:3], normal_d_arr[3])\n",
    "    else:\n",
    "        normal_d_tuple = None\n",
    "\n",
    "    with open(os.path.join(temp_dir, \"visualizer_config.json\")) as f:\n",
    "        config = json.load(f)\n",
    "\n",
    "    visualizer = PointCloudVisualizer(\n",
    "        point_size=config.get(\"point_size\", 1.0),\n",
    "        grid_size=config.get(\"grid_size\", 50),\n",
    "        grid_spacing=config.get(\"grid_spacing\", 1.0),\n",
    "        grid_line_width=config.get(\"grid_line_width\", 10),\n",
    "        cluster_viz=config.get(\"cluster_viz\", False),\n",
    "    )\n",
    "\n",
    "    visualizer.show(\n",
    "        point_cloud,\n",
    "        normal_d_tuple=normal_d_tuple,\n",
    "        show_plane=config.get(\"show_plane\", False),\n",
    "        show_grid=config.get(\"show_grid\", False),\n",
    "        show_ground=config.get(\"show_ground\", True),\n",
    "        show_clusters=config.get(\"show_clusters\", True),\n",
    "        show_unlabeled=config.get(\"show_unlabeled\", True),\n",
    "        show_true_label=config.get(\"show_true_label\", False),\n",
    "    )\n",
    "\n",
    "    # Limpar diretório temporário\n",
    "    if os.path.exists(temp_dir):\n",
    "        shutil.rmtree(temp_dir)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if len(sys.argv) > 1:\n",
    "        main_viz(sys.argv[1])\n",
    "    else:\n",
    "        print(\"No temporary directory provided. Exiting.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3006ca",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11dd636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def save_clusters(\n",
    "    point_cloud: np.ndarray, seq: str, frame_id: str, output_base_path: str\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Salva os rótulos preditos em formato .label seguindo a estrutura do SemanticKITTI.\n",
    "\n",
    "    Args:\n",
    "        point_cloud (np.ndarray): Array Nx6 com colunas [x, y, z, true_label, predicted_label, scanline_index].\n",
    "        seq (str): Número da sequência (ex: '00', '01', ...).\n",
    "        frame_id (str): ID do frame (ex: '000123').\n",
    "        output_base_path (str): Caminho base até `data_odometry_cluster_pred/dataset/sequences`.\n",
    "    \"\"\"\n",
    "    # Extrair coluna de predição (índice 4)\n",
    "    predicted_labels = point_cloud[:, 4].astype(np.uint32)\n",
    "\n",
    "    # Construir caminho de saída\n",
    "    output_dir = Path(output_base_path) / seq / \"clusters\"\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Nome do arquivo com sufixo _pred.label\n",
    "    output_file = output_dir / f\"{frame_id}_cluster.label\"\n",
    "\n",
    "    # Salvar como arquivo binário .label\n",
    "    predicted_labels.tofile(output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b220da2e",
   "metadata": {},
   "source": [
    "# Result analisys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ac2544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def verificar_consistencia_labels(pontos):\n",
    "    \"\"\"\n",
    "    Verifica inconsistências entre rótulos verdadeiros e clusters atribuídos.\n",
    "    Também calcula estatísticas (média e desvio padrão) dos clusters inconsistentes.\n",
    "\n",
    "    Entrada:\n",
    "        pontos (np.ndarray): Array N x 6 contendo [x, y, z, true_label, pred_label, scanline_id].\n",
    "\n",
    "    Retorna:\n",
    "        - inconsistentes_total (int): Número de clusters inconsistentes encontrados.\n",
    "        - combinacoes_contadas (Counter): Contagem de combinações de labels inconsistentes.\n",
    "        - estatisticas_erro (dict): Médias e desvios padrão das métricas de erro, mais erro do cluster 9.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extrai o vetor de labels preditos dos pontos (coluna 4)\n",
    "    labels_pred = pontos[:, 4].astype(int)  # Exemplo: [1, 1, 2, 2, 3]\n",
    "\n",
    "    # Extrai o vetor de labels verdadeiros dos pontos (coluna 3)\n",
    "    labels_true = pontos[:, 3].astype(int)  # Exemplo: [2, 2, 6, 6, 9]\n",
    "\n",
    "    # Combina predição e verdade em pares (pred_label, true_label) para cada ponto\n",
    "    pares = np.stack((labels_pred, labels_true), axis=1)\n",
    "    # Exemplo de pares:\n",
    "    # [[1, 2],\n",
    "    #  [1, 2],\n",
    "    #  [2, 6],\n",
    "    #  [2, 6],\n",
    "    #  [3, 9]]\n",
    "\n",
    "    # Cria um dicionário para mapear cada cluster predito para a lista de true_labels associados\n",
    "    # Exemplo após o preenchimento:\n",
    "    # cluster_to_true_labels = {\n",
    "    #     1: [2, 2],\n",
    "    #     2: [6, 6],\n",
    "    #     3: [9]\n",
    "    # }\n",
    "    cluster_to_true_labels = defaultdict(list)\n",
    "    for cluster_id, true_label in pares:\n",
    "        cluster_to_true_labels[cluster_id].append(true_label)\n",
    "\n",
    "    # Lista para armazenar combinações de labels inconsistentes\n",
    "    combinacoes = []\n",
    "\n",
    "    # Contador de clusters inconsistentes\n",
    "    inconsistentes_total = 0\n",
    "\n",
    "    # Listas para armazenar métricas de erro dos clusters inconsistentes\n",
    "    lista_total_pontos = []  # Exemplo: [10, 15]\n",
    "    lista_pontos_label_dominante = []  # Exemplo: [7, 12]\n",
    "    lista_erro_percentual = []  # Exemplo: [30.0, 20.0]\n",
    "\n",
    "    # Variável para armazenar o erro percentual do cluster 9 (solo)\n",
    "    erro_percentual_cluster_9 = None\n",
    "\n",
    "    # Itera sobre cada cluster_id e sua lista de true_labels\n",
    "    for cluster_id, labels in cluster_to_true_labels.items():\n",
    "\n",
    "        # Ignora o cluster 9, pois será tratado separadamente\n",
    "        if cluster_id == 9:\n",
    "            continue\n",
    "\n",
    "        # Remove pontos sem rótulo (label 0)\n",
    "        labels_sem_unlabeled = [l for l in labels if l != 0]\n",
    "        # Exemplo: se labels = [0, 2, 2, 3], labels_sem_unlabeled = [2, 2, 3]\n",
    "\n",
    "        # Verifica se existem múltiplos labels (inconsistência no cluster)\n",
    "        #\n",
    "        # labels_sem_unlabeled é uma lista que contém os rótulos verdadeiros (true_labels) dos pontos de um cluster, ignorando os rótulos \"0\" (não rotulados).\n",
    "        #\n",
    "        # A função set() em Python transforma a lista em um conjunto, ou seja, remove todos os elementos repetidos.\n",
    "        # Por exemplo:\n",
    "        #   labels_sem_unlabeled = [2, 2, 2] → set(labels_sem_unlabeled) = {2} (apenas um elemento)\n",
    "        #   labels_sem_unlabeled = [2, 2, 3] → set(labels_sem_unlabeled) = {2, 3} (dois elementos diferentes)\n",
    "        #\n",
    "        # Depois, usamos len(set(...)) para contar quantos elementos únicos existem.\n",
    "        #\n",
    "        # Se existir mais de 1 label diferente (len > 1), isso significa que o cluster está inconsistente — porque ele deveria ter apenas pontos de um único tipo (um único rótulo verdadeiro).\n",
    "        if len(set(labels_sem_unlabeled)) > 1:\n",
    "            inconsistentes_total += 1  # Incrementa o contador\n",
    "\n",
    "            # Cria uma combinação ordenada dos labels para contagem\n",
    "            combinacao = tuple(sorted(set(labels_sem_unlabeled)))\n",
    "            # Exemplo: (2, 3)\n",
    "\n",
    "            combinacoes.append(combinacao)\n",
    "\n",
    "            # Estatísticas para o cluster inconsistente:\n",
    "\n",
    "            # Número total de pontos no cluster\n",
    "            total_pontos = len(labels)\n",
    "\n",
    "            # Conta quantos pontos existem para cada true_label\n",
    "            #\n",
    "            # labels_sem_unlabeled é a lista de rótulos verdadeiros dos pontos dentro de um cluster (ignorando os 0s).\n",
    "            #\n",
    "            # Usamos Counter(labels_sem_unlabeled) para contar quantas vezes cada label aparece.\n",
    "            # Counter é uma ferramenta do Python que cria automaticamente um \"dicionário de contagem\".\n",
    "            #\n",
    "            # Exemplo:\n",
    "            # labels_sem_unlabeled = [2, 2, 3]\n",
    "            # Então, contador_labels = Counter({2: 2, 3: 1})\n",
    "            # Significa que o label 2 aparece 2 vezes e o label 3 aparece 1 vez.\n",
    "            contador_labels = Counter(labels_sem_unlabeled)\n",
    "\n",
    "            # Identifica o label dominante (aquele com mais pontos)\n",
    "            #\n",
    "            # Depois de contar quantos pontos existem para cada label, queremos saber qual label aparece mais vezes — o dominante.\n",
    "            #\n",
    "            # Usamos contador_labels.most_common(1) para pegar o label mais frequente.\n",
    "            # Isso retorna uma lista com o (label, quantidade), e o [0] serve para pegar o primeiro (e único) elemento dessa lista.\n",
    "            #\n",
    "            # Exemplo:\n",
    "            # contador_labels = Counter({2: 2, 3: 1})\n",
    "            # contador_labels.most_common(1) = [(2, 2)]\n",
    "            # Ou seja:\n",
    "            #   label_dominante = 2  (o label que mais aparece)\n",
    "            #   pontos_label_dominante = 2  (quantas vezes ele aparece)\n",
    "            label_dominante, pontos_label_dominante = contador_labels.most_common(1)[0]\n",
    "\n",
    "            # Calcula o erro percentual (percentual de pontos errados)\n",
    "            erro_percentual = 100 * (1 - (pontos_label_dominante / total_pontos))\n",
    "            # Exemplo: erro_percentual = 100 * (1 - 2/3) ≈ 33.33%\n",
    "\n",
    "            # Armazena para cálculo posterior de média e desvio padrão\n",
    "            lista_total_pontos.append(total_pontos)\n",
    "            lista_pontos_label_dominante.append(pontos_label_dominante)\n",
    "            lista_erro_percentual.append(erro_percentual)\n",
    "\n",
    "    # Conta quantas vezes cada combinação de labels inconsistentes apareceu\n",
    "    combinacoes_contadas = Counter(combinacoes)\n",
    "    # Exemplo: Counter({(2, 3): 1, (6, 7): 2})\n",
    "\n",
    "    # ---- Cálculo especial para o cluster 9 (chão) ----\n",
    "\n",
    "    # Pega todos os true_labels associados ao cluster 9\n",
    "    labels = cluster_to_true_labels[9]\n",
    "    # Exemplo: labels = [9, 9, 9, 5] (erro no último)\n",
    "\n",
    "    # Número total de pontos no cluster 9\n",
    "    total_pontos_cluster_9 = len(labels)\n",
    "\n",
    "    # Conta quantos pontos têm erro (não são 9)\n",
    "    num_erros_cluster_9 = sum(1 for l in labels if l != 9)\n",
    "\n",
    "    # Calcula o erro percentual do cluster 9\n",
    "    if total_pontos_cluster_9 > 0:\n",
    "        erro_percentual_cluster_9 = 100 * (num_erros_cluster_9 / total_pontos_cluster_9)\n",
    "        # Exemplo: 1 erro em 4 pontos → 25%\n",
    "    else:\n",
    "        erro_percentual_cluster_9 = 0.0\n",
    "\n",
    "    # ---- Cálculo das estatísticas gerais ----\n",
    "\n",
    "    # Se existirem clusters inconsistentes\n",
    "    if inconsistentes_total > 0:\n",
    "        estatisticas_erro = {\n",
    "            \"media_total_pontos\": np.mean(\n",
    "                lista_total_pontos\n",
    "            ),  # Média do total de pontos nos clusters inconsistentes\n",
    "            \"std_total_pontos\": np.std(\n",
    "                lista_total_pontos\n",
    "            ),  # Desvio padrão do total de pontos\n",
    "            \"media_pontos_label_dominante\": np.mean(\n",
    "                lista_pontos_label_dominante\n",
    "            ),  # Média de pontos no label dominante\n",
    "            \"std_pontos_label_dominante\": np.std(\n",
    "                lista_pontos_label_dominante\n",
    "            ),  # Desvio padrão dos pontos dominantes\n",
    "            \"media_erro_percentual\": np.mean(\n",
    "                lista_erro_percentual\n",
    "            ),  # Média dos erros percentuais\n",
    "            \"std_erro_percentual\": np.std(\n",
    "                lista_erro_percentual\n",
    "            ),  # Desvio padrão dos erros percentuais\n",
    "            \"erro_percentual_cluster_9\": erro_percentual_cluster_9,  # Erro no cluster do chão\n",
    "        }\n",
    "    else:\n",
    "        # Se não houver inconsistências, inicializa as métricas com zero\n",
    "        estatisticas_erro = {\n",
    "            \"media_total_pontos\": 0,\n",
    "            \"std_total_pontos\": 0,\n",
    "            \"media_pontos_label_dominante\": 0,\n",
    "            \"std_pontos_label_dominante\": 0,\n",
    "            \"media_erro_percentual\": 0,\n",
    "            \"std_erro_percentual\": 0,\n",
    "            \"erro_percentual_cluster_9\": erro_percentual_cluster_9,\n",
    "        }\n",
    "\n",
    "    # Retorna o número de inconsistências, as combinações contadas e as estatísticas calculadas\n",
    "    return inconsistentes_total, combinacoes_contadas, estatisticas_erro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5623b3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def get_statistics(idx, point_cloud):\n",
    "    clusters = point_cloud[:, 4]\n",
    "    num_clusters = len(np.unique(clusters))\n",
    "    num_pontos = point_cloud.shape[0]\n",
    "\n",
    "    cluster_sizes = [np.sum(clusters == label) for label in np.unique(clusters)]\n",
    "    cluster_sizes_sorted = sorted(cluster_sizes, reverse=True)\n",
    "\n",
    "    ground_cluster_size = np.sum(clusters == 9)\n",
    "    largest_non_ground_cluster = (\n",
    "        cluster_sizes_sorted[1]\n",
    "        if cluster_sizes_sorted[0] == ground_cluster_size\n",
    "        and len(cluster_sizes_sorted) > 1\n",
    "        else cluster_sizes_sorted[0]\n",
    "    )\n",
    "\n",
    "    num_clusters_inconsistentes, combinacoes, erros_clusters = (\n",
    "        verificar_consistencia_labels(point_cloud)\n",
    "    )\n",
    "\n",
    "    estatisticas_do_frame = {\n",
    "        \"frame_id\": idx,\n",
    "        \"num_clusters\": num_clusters,\n",
    "        \"num_pontos\": num_pontos,\n",
    "        \"pontos_por_cluster_medio\": (\n",
    "            num_pontos / num_clusters if num_clusters > 0 else 0\n",
    "        ),\n",
    "        \"largest_non_ground_cluster\": largest_non_ground_cluster,\n",
    "        \"gound_cluster_size\": ground_cluster_size,\n",
    "        \"num_clusters_inconsistentes\": num_clusters_inconsistentes,  # Novo campo\n",
    "        \"combinacoes\": combinacoes,\n",
    "        \"erros_clusters\": erros_clusters,\n",
    "    }\n",
    "\n",
    "    return estatisticas_do_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7105856",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2d4e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def _plot_with_stats(\n",
    "    ax,\n",
    "    x,\n",
    "    y,\n",
    "    color,\n",
    "    label,\n",
    "    title,\n",
    "    ylabel,\n",
    "    linestyle=\"o\",\n",
    "    mean_fmt=\"{:.1f}\",\n",
    "    std_fmt=\"{:.1f}\",\n",
    "):\n",
    "    \"\"\"Função auxiliar para plotar métricas com média e desvio padrão.\"\"\"\n",
    "    media = np.mean(y)\n",
    "    desvio = np.std(y)\n",
    "    ax.plot(x, y, marker=linestyle, label=label, color=color)\n",
    "    ax.axhline(\n",
    "        media, color=color, linestyle=\"--\", label=f\"Média = {mean_fmt.format(media)}\"\n",
    "    )\n",
    "    ax.fill_between(\n",
    "        x,\n",
    "        media - desvio,\n",
    "        media + desvio,\n",
    "        color=color,\n",
    "        alpha=0.2,\n",
    "        label=f\"Desvio = {std_fmt.format(desvio)}\",\n",
    "    )\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Frame\")\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.legend()\n",
    "    ax.grid(axis=\"y\", color=\"gray\", linestyle=\"--\", linewidth=0.7, alpha=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36196fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def plot_1(resumo_por_frame, seq_value=None):\n",
    "    \"\"\"\n",
    "    Plota em 4 subplots verticais:\n",
    "    1. Número total de pontos\n",
    "    2. Número total de clusters\n",
    "    3. Pontos por cluster médio\n",
    "    4. Porcentagem de redução da dimensionalidade\n",
    "    \"\"\"\n",
    "    num_clusters = np.array([frame[\"num_clusters\"] for frame in resumo_por_frame])\n",
    "    num_pontos = np.array([frame[\"num_pontos\"] for frame in resumo_por_frame])\n",
    "    pontos_por_cluster_medio = np.array(\n",
    "        [frame[\"pontos_por_cluster_medio\"] for frame in resumo_por_frame]\n",
    "    )\n",
    "    frames = np.arange(len(resumo_por_frame))\n",
    "    reducao_dimensionalidade = 1 - (num_clusters / num_pontos)\n",
    "\n",
    "    fig, axs = plt.subplots(4, 1, figsize=(12, 18))\n",
    "    fig.tight_layout(pad=5.0)\n",
    "\n",
    "    _plot_with_stats(\n",
    "        axs[0],\n",
    "        frames,\n",
    "        num_pontos,\n",
    "        \"green\",\n",
    "        \"Número de Pontos\",\n",
    "        \"Número de Pontos por Frame\",\n",
    "        \"Número de Pontos\",\n",
    "    )\n",
    "    _plot_with_stats(\n",
    "        axs[1],\n",
    "        frames,\n",
    "        num_clusters,\n",
    "        \"blue\",\n",
    "        \"Número de Clusters\",\n",
    "        \"Número de Clusters por Frame\",\n",
    "        \"Número de Clusters\",\n",
    "    )\n",
    "    _plot_with_stats(\n",
    "        axs[2],\n",
    "        frames,\n",
    "        pontos_por_cluster_medio,\n",
    "        \"orange\",\n",
    "        \"Pontos por Cluster Médio\",\n",
    "        \"Média de Pontos por Cluster por Frame\",\n",
    "        \"Pontos por Cluster\",\n",
    "    )\n",
    "    _plot_with_stats(\n",
    "        axs[3],\n",
    "        frames,\n",
    "        reducao_dimensionalidade * 100,\n",
    "        \"purple\",\n",
    "        \"Redução Dimensionalidade (%)\",\n",
    "        \"Porcentagem de Redução da Dimensionalidade por Frame\",\n",
    "        \"Redução (%)\",\n",
    "        mean_fmt=\"{:.2f}\",\n",
    "        std_fmt=\"{:.2f}\",\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    if seq_value is not None:\n",
    "        plot_dir = Path(\"plots\") / str(seq_value)\n",
    "        plot_dir.mkdir(parents=True, exist_ok=True)\n",
    "        fig.savefig(plot_dir / \"plot-1.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f28b501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def plot_2(resumo_por_frame, seq_value=None):\n",
    "    ground_cluster_size = [f[\"gound_cluster_size\"] for f in resumo_por_frame]\n",
    "    largest_non_ground_cluster = [\n",
    "        f[\"largest_non_ground_cluster\"] for f in resumo_por_frame\n",
    "    ]\n",
    "    frames = np.arange(len(resumo_por_frame))\n",
    "\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(12, 10), sharex=True)\n",
    "    _plot_with_stats(\n",
    "        axs[0],\n",
    "        frames,\n",
    "        ground_cluster_size,\n",
    "        \"green\",\n",
    "        \"Ground cluster\",\n",
    "        \"Tamanho do Ground Cluster\",\n",
    "        \"Tamanho\",\n",
    "    )\n",
    "    _plot_with_stats(\n",
    "        axs[1],\n",
    "        frames,\n",
    "        largest_non_ground_cluster,\n",
    "        \"blue\",\n",
    "        \"Maior non ground cluster\",\n",
    "        \"Tamanho do Maior non Ground Cluster\",\n",
    "        \"Tamanho\",\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    if seq_value is not None:\n",
    "        plot_dir = Path(\"plots\") / str(seq_value)\n",
    "        plot_dir.mkdir(parents=True, exist_ok=True)\n",
    "        fig.savefig(plot_dir / \"plot-2.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dacd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def plot_3(resumo_por_frame, seq_value=None):\n",
    "    inconsistentes_por_frame = np.array(\n",
    "        [frame[\"num_clusters_inconsistentes\"] for frame in resumo_por_frame]\n",
    "    )\n",
    "    num_clusters_por_frame = np.array(\n",
    "        [frame[\"num_clusters\"] for frame in resumo_por_frame]\n",
    "    )\n",
    "    frames = np.arange(len(resumo_por_frame))\n",
    "\n",
    "    porcentagem_erro = 1 - (inconsistentes_por_frame / num_clusters_por_frame)\n",
    "    porcentagem_erro = np.clip(porcentagem_erro, 0, 1)\n",
    "\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(10, 10), sharex=True)\n",
    "    _plot_with_stats(\n",
    "        axs[0],\n",
    "        frames,\n",
    "        inconsistentes_por_frame,\n",
    "        \"red\",\n",
    "        \"Inconsistências por frame\",\n",
    "        \"Clusters Inconsistentes por Frame\",\n",
    "        \"Nº de Clusters Inconsistentes\",\n",
    "        mean_fmt=\"{:.2f}\",\n",
    "        std_fmt=\"{:.2f}\",\n",
    "    )\n",
    "    _plot_with_stats(\n",
    "        axs[1],\n",
    "        frames,\n",
    "        porcentagem_erro,\n",
    "        \"green\",\n",
    "        \"Porcentagem de acerto\",\n",
    "        \"Porcentagem de Erro por Frame\",\n",
    "        \"Porcentagem de Erro\",\n",
    "        mean_fmt=\"{:.2f}\",\n",
    "        std_fmt=\"{:.2f}\",\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    if seq_value is not None:\n",
    "        plot_dir = Path(\"plots\") / str(seq_value)\n",
    "        plot_dir.mkdir(parents=True, exist_ok=True)\n",
    "        fig.savefig(plot_dir / \"plot-3.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea3b2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def plot_4(resumo_por_frame, seq_value=None):\n",
    "    \"\"\"\n",
    "    Plota sete métricas de erro em subplots separados no mesmo figure.\n",
    "    \"\"\"\n",
    "    # Cada métrica: (chave_media, chave_std, título_média, título_std, ylabel)\n",
    "    metricas = [\n",
    "        (\n",
    "            \"media_total_pontos\",\n",
    "            \"std_total_pontos\",\n",
    "            \"Média: Total de Pontos nos Clusters Inconsistentes por Frame\",\n",
    "            \"Desvio: Total de Pontos nos Clusters Inconsistentes por Frame\",\n",
    "            \"Total de Pontos\",\n",
    "        ),\n",
    "        (\n",
    "            \"media_pontos_label_dominante\",\n",
    "            \"std_pontos_label_dominante\",\n",
    "            \"Média: Pontos do Label Dominante por Cluster Inconsistente\",\n",
    "            \"Desvio: Pontos do Label Dominante por Cluster Inconsistente\",\n",
    "            \"Pontos do Label Dominante\",\n",
    "        ),\n",
    "        (\n",
    "            \"media_erro_percentual\",\n",
    "            \"std_erro_percentual\",\n",
    "            \"Média: Erro Percentual nos Clusters Inconsistentes por Frame\",\n",
    "            \"Desvio: Erro Percentual nos Clusters Inconsistentes por Frame\",\n",
    "            \"Erro Percentual (%)\",\n",
    "        ),\n",
    "        (\n",
    "            \"erro_percentual_cluster_9\",\n",
    "            None,\n",
    "            \"Erro Percentual no Cluster de Solo (Ground) por Frame\",\n",
    "            None,\n",
    "            \"Erro Percentual no Solo (%)\",\n",
    "        ),\n",
    "    ]\n",
    "    frames = np.arange(len(resumo_por_frame))\n",
    "    fig, axs = plt.subplots(7, 1, figsize=(14, 28))\n",
    "    fig.tight_layout(pad=5.0)\n",
    "    plot_idx = 0\n",
    "\n",
    "    for chave_media, chave_std, titulo_media, titulo_std, ylabel in metricas:\n",
    "        # Plot média\n",
    "        valores_media = np.array(\n",
    "            [frame[\"erros_clusters\"][chave_media] for frame in resumo_por_frame]\n",
    "        )\n",
    "        _plot_with_stats(\n",
    "            axs[plot_idx],\n",
    "            frames,\n",
    "            valores_media,\n",
    "            \"red\",\n",
    "            f\"{ylabel} (média) por frame\",\n",
    "            titulo_media,\n",
    "            ylabel,\n",
    "            mean_fmt=\"{:.2f}\",\n",
    "            std_fmt=\"{:.2f}\",\n",
    "        )\n",
    "        plot_idx += 1\n",
    "        # Plot std se existir\n",
    "        if chave_std:\n",
    "            valores_std = np.array(\n",
    "                [frame[\"erros_clusters\"][chave_std] for frame in resumo_por_frame]\n",
    "            )\n",
    "            _plot_with_stats(\n",
    "                axs[plot_idx],\n",
    "                frames,\n",
    "                valores_std,\n",
    "                \"purple\",\n",
    "                f\"{ylabel} (desvio) por frame\",\n",
    "                titulo_std,\n",
    "                f\"Desvio de {ylabel}\",\n",
    "                mean_fmt=\"{:.2f}\",\n",
    "                std_fmt=\"{:.2f}\",\n",
    "            )\n",
    "            plot_idx += 1\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    if seq_value is not None:\n",
    "        plot_dir = Path(\"plots\") / str(seq_value)\n",
    "        plot_dir.mkdir(parents=True, exist_ok=True)\n",
    "        fig.savefig(plot_dir / \"plot-4.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4997ae77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def plot_5(combinacoes_geral, seq_value=None, top_n=15):\n",
    "    label_id_to_name = {\n",
    "        -1: \"plane\",\n",
    "        0: \"unlabeled\",\n",
    "        1: \"car\",\n",
    "        2: \"bicycle\",\n",
    "        3: \"motorcycle\",\n",
    "        4: \"truck\",\n",
    "        5: \"other-vehicle\",\n",
    "        6: \"person\",\n",
    "        7: \"bicyclist\",\n",
    "        8: \"motorcyclist\",\n",
    "        9: \"road\",\n",
    "        10: \"parking\",\n",
    "        11: \"sidewalk\",\n",
    "        12: \"other-ground\",\n",
    "        13: \"building\",\n",
    "        14: \"fence\",\n",
    "        15: \"vegetation\",\n",
    "        16: \"trunk\",\n",
    "        17: \"terrain\",\n",
    "        18: \"pole\",\n",
    "        19: \"traffic-sign\",\n",
    "    }\n",
    "\n",
    "    combinacoes_ordenadas = sorted(\n",
    "        combinacoes_geral.items(), key=lambda x: x[1], reverse=True\n",
    "    )\n",
    "    top_combinacoes = combinacoes_ordenadas[:top_n]\n",
    "\n",
    "\n",
    "    def formatar_combinacao(combinacao):\n",
    "        nomes = [label_id_to_name.get(int(l), f\"desconhecido({l})\") for l in combinacao]\n",
    "        return \", \".join(nomes)\n",
    "\n",
    "    labels_pizza = [formatar_combinacao(comb) for comb, _ in top_combinacoes]\n",
    "    valores_pizza = [contagem for _, contagem in top_combinacoes]\n",
    "\n",
    "    total = sum(combinacoes_geral.values())\n",
    "    total_top = sum(valores_pizza)\n",
    "    outros = total - total_top\n",
    "\n",
    "    if outros > 0:\n",
    "        labels_pizza.append(\"Outros\")\n",
    "        valores_pizza.append(outros)\n",
    "\n",
    "    colors = cm.get_cmap(\"tab20\")(np.linspace(0, 1, len(labels_pizza)))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "    # Calcula as porcentagens de cada fatia\n",
    "    valores_pizza = np.array(valores_pizza)\n",
    "    porcentagens = 100 * valores_pizza / valores_pizza.sum()\n",
    "\n",
    "    # Função para mostrar porcentagem só se o slice for maior que 3%\n",
    "    def autopct_format(pct):\n",
    "        return (\"%1.1f%%\" % pct) if pct > 3 else \"\"\n",
    "\n",
    "    wedges, texts, autotexts = ax.pie( # type: ignore\n",
    "        valores_pizza,\n",
    "        labels=None,  # Não mostra os labels diretamente\n",
    "        autopct=autopct_format,\n",
    "        startangle=140,\n",
    "        colors=colors, # type: ignore\n",
    "        pctdistance=0.8,\n",
    "        wedgeprops=dict(edgecolor=\"w\", linewidth=1),\n",
    "        textprops=dict(fontsize=14, color=\"black\"),\n",
    "    )\n",
    "\n",
    "    # Monta a legenda em colunas, porcentagens pequenas vão ao lado do nome\n",
    "    legend_labels = []\n",
    "    for nome, pct in zip(labels_pizza, porcentagens):\n",
    "        legend_labels.append(f\"{nome} ({pct:.1f}%)\")\n",
    "\n",
    "    # Calcula número de colunas para legenda (máx 5 por coluna)\n",
    "    n_labels = len(legend_labels)\n",
    "    ncol = min(3, max(1, (n_labels + 4) // 5))  # até 5 linhas por coluna\n",
    "\n",
    "    ax.set_title(f\"Top {top_n} combinações inconsistentes + Outros\", fontsize=20, pad=20)\n",
    "    ax.axis(\"equal\")\n",
    "\n",
    "    # Legenda embaixo, em colunas, centralizada\n",
    "    fig.legend(\n",
    "        wedges,\n",
    "        legend_labels,\n",
    "        title=\"Combinações\",\n",
    "        loc=\"lower center\",\n",
    "        bbox_to_anchor=(0.5, -0.08),\n",
    "        fontsize=14,\n",
    "        title_fontsize=16,\n",
    "        frameon=False,\n",
    "        ncol=ncol,\n",
    "        columnspacing=1.5,\n",
    "        handlelength=1.5,\n",
    "    )\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.08, 1, 1])  # type: ignore \n",
    "\n",
    "    plt.show()\n",
    "    if seq_value is not None:\n",
    "        Path(\"plots\").mkdir(parents=True, exist_ok=True)\n",
    "        Path(f\"plots/{seq_value}\").mkdir(parents=True, exist_ok=True)\n",
    "        fig.savefig(f\"plots/{seq_value}/plot-5.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
